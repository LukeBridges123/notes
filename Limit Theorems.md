# Gaussian Approximations
## Binomial Distribution
Take the binomial distribution for a fair coin flip, $B(n, 0.5)$. For convenience, we will let the total number of trials be $2n$, and instead of measuring the number of successes, we will measure the difference between the actual number $x$ of successes and the expected number $n$. This will give us a mean of $0$ for any $n$, thus avoiding annoyances due to the mean increasing as we increase $n$. 

In this notation, we can write the probability that we succeed $x$ more (or fewer, if $x$ is negative) times than $n$ as $P(x) = (1/2)^{x+n}(1/2)^{n - x} \binom{2n}{x + n} = \frac{1}{2^{2n}}\binom{2n}{x+n}$.

Now we approximate the binomial coefficient using Stirling's approximation, $n! \approx n^n e^{-n} \sqrt{2\pi n}$. We then have $\binom{2n}{x+n} = \frac{(2n)!}{(x+n)!(x-n)!} \approx \frac{(2n)^{2n} e^{-2n} \sqrt{2\pi \cdot 2n}}{(n+x)^{n+x}e^{-(n+x)}\sqrt{2\pi(n+x)}(n-x)^{-(n-x)}e^{n-x}\sqrt{2\pi(n-x)}}$. Combining the $e$ terms in the denominator gets us $e^{-n-x}e^{-n+x} = e^{-2n}$ which cancels with the $e$ term in the numerator. The $\sqrt{4\pi}$ in the numerator cancels with $\sqrt{4\pi^2}$ in the denominator, leaving $\sqrt{\pi}$. Thus, making all these cancellations and rearranging further, we get $\frac{(2n)^{2n}\sqrt{n}}{(n+x)^{n+x}(n-x)^{n-x}\sqrt{\pi(n^2 - x^2})}$.

To handle the first two terms in the denominator, we will need an approximation for expressions like $(1 + a)^m$. Taking logs and using the series for $\ln(1+x)$, we get $m(a - \frac{a^2}{2} + \dots)$, which we can truncate to just $ma - \frac{ma^2}{2}$; exponentiating both sides we get $(1 + a)^m \approx \exp(ma)\exp(-ma^2/2) = \exp(ma - \frac{ma^2}{2})$. If we pull a factor of $n$ out of the parentheses for both terms in the denominator we get $n^{n+x}(1 + \frac{x}{n})^{n+x}n^{n-x}(1 - \frac{x}{n})^{n-x} = n^{2n}(1 + \frac{x}{n})^{n+x}(1 - \frac{x}{n})^{n-x}$, and can now apply that approximation we just mentioned. In the first case we get $(1 + \frac{x}{n})^{n+x} \approx \exp((n+x)\frac{x}{n} - \frac{1}{2}(n+x)\frac{x^2}{n^2}=\exp(x+\frac{x^2}{n}-\frac{x^2}{2n}-\frac{x^3}{2n^2})$. Note that we can neglect that $x^3$ term by assuming that $x$ is substantially smaller than $n$, i.e. the number of successes is close to $n$--for large $n$, the probability that the number of successes deviates from $n$ is very small, so we'll concentrate only at terms near the middle of the distribution, where $x$ is small compared to $n$. We thus get $\exp(x + \frac{x^2}{2n})$. Similar calculations show that the second term is approximately $\exp(-x + \frac{x^2}{2n})$. For the third term, we can again use the approximation that $x$ is much less than $n$ to get $\sqrt{\pi (n^2 - x^2)} \approx \sqrt{\pi n^2} = n\sqrt{\pi}$. 

Substituting this back into $\frac{(2n)^{2n}\sqrt{n}}{(n+x)^{n+x}(n-x)^{n-x}\sqrt{\pi(n^2 - x^2})}$ gets us $\frac{(2n)^{2n}\sqrt{n}}{n^{2n}\exp(x + \frac {x^2}{2n})\exp(-x + \frac{x^2}{2n})n\sqrt{\pi}}$. Cancelling the leftmost terms of the numerator and denominator, combining the $\exp$ terms, and dividing the $\sqrt{n}$ in then numerator by the $n$ in the denominator gets us $\frac{2^{2n}}{\sqrt{n\pi}\exp(x^2/n)}$. What all this shows is that $\binom{2n}{n+x} \approx \frac{2^{2n}}{\sqrt{n\pi}}e^{-x^2/n}$, so the probability of any given $x$ is $\frac{e^{-x^2/n}}{\sqrt{n\pi}}$. This is exactly a Gaussian with $\mu = 0, b = \frac{1}{n}$, as desired. 
## Poisson Distribution

# Law of Large Numbers
....

For a simple special case of this, consider flipping a biased coin which comes up heads with probability $p$. Then the law of large numbers says that, for any $\epsilon, \delta > 0$, there exists $n$ such that, letting $X_n$ be a random variable equal to the number of heads in $n$ coin tosses, we have $P(|X_n/n - p| > \delta) < \epsilon$. In other words, as the number of coin flips grows large, the probability that the proportion of heads in the sample differs from $p$ by more than some fixed error $\delta$ converges to $0$. 

$X_n$ is just a binomial distribution $B(n, p)$, so we can prove this using the result about Gaussian approximations above, or we can get a more direct proof using [[Random Variables#Chebyshev's Inequality|Chebyshev's inequality]]. Our binomial random variable $X_n$ has a mean of $np$ and standard deviation of $\sqrt{np(1-p)}$, so $X_n/n$ has a mean of $\mu = p$ and a standard deviation of $\sigma = \frac{\sqrt{p(1-p)}}{\sqrt{n}}$. Chebyshev's inequality then says that $P(|X_n/n - \mu| > k\sigma) < \frac{1}{k^2}$. So, given $\epsilon$ and $\delta$, choose $k > 1$ large enough that $\frac{1}{k^2} < \epsilon$. We want to have $\delta < k\sigma$ .........
# Central Limit Theorem
