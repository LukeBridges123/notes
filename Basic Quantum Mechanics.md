$\newcommand{\ket}[1]{|#1 \rangle}$
$\newcommand{\bra}[1]{\langle #1 |}$
$\newcommand{\tr}{\operatorname{tr}}$ 
$\newcommand{\ol}{\overline}$ 
# Quantum Mechanics for Qubits
First we consider the postulates of QM in a more specific and concrete context: systems of qubits, with measurements in the computational basis.

## States, Measurements, and Operations on Single Qubits
A qubit has at least the states of a classical bit, $0$ and $1$ (represented in bra-ket notation as $\ket{0}$ and $\ket{1}$), and can also take on any superposition of those states, $a\ket{0} + b\ket{1}$ where $a, b$ are complex numbers with $|a|^2 + |b|^2 = 1$. The exact physical meaning of those states depends on how the qubit is implemented. More abstractly, a qubit is a unit vector in a 2-dimensional complex vector space. There is some orthonormal basis, called the "computational basis" and denoted by $\ket{0}, \ket{1}$, with the property that, if a qubit's state is $\ket{0}$, it will always give a $0$ when measured (whatever that means in the particular physical context), and the same for $1$. 

Now we know, at least, how measurements work when the qubit is in one of the computational basis states. In a general superposition $a\ket{0} + b\ket{1}$, we get a $0$ with probability $|a|^2$ and a $1$ with probability $|b|^2$. The state then changes to just $\ket{0}$ or $\ket{1}$ depending on the outcome ("collapse").

Thinking of $a$ and $b$ as being "complex probabilities", we now see why we have the requirement that the qubit is a unit vector: in the computational basis, the squares of the absolute values of its components are probabilities, and so should sum to $1$. This also seems to imply that operations on qubits should take unit vectors to unit vectors, i.e. should be unitary operators, represented in the computational basis as unitary matrices. One implication of this, which will be more important once we get to systems of qubits, is that operations must be reversible or invertible--hence the inability to get direct analogues of some operations on classical bits, like AND-gates. 

On the other hand we do have a quantum analogue of the NOT-gate. Its matrix in the computational basis is $\MatrixTwoTwo{0}{1}{1}{0}$; thus it sends $\ket{0}$ to $\ket{1}$ and vice versa. More generally it sends a superposition $a\ket{0} + b\ket{1}$ to $b\ket{0} + a\ket{1}$. Note that this is also called $X$, and along with $Y = \MatrixTwoTwo{0}{-i}{i}{0}$ and $Z = \MatrixTwoTwo{1}{0}{0}{-1}$, it is one of the "Pauli matrices". 

We also have some more distinctly "quantum" operations, without much of a classical analogue. For example, there is the Hadamard gate, $H = \frac{1}{\sqrt{2}}\MatrixTwoTwo{1}{1}{1}{-1}$. This transforms $\ket{0}$ and $\ket{1}$ into the states often denoted $\ket{+} = \frac{\ket{0} + \ket{1}}{2}$, $\ket{-} = \frac{\ket{0} - \ket{1}}{2}$. Note that this can be used to perform a classical "coin flip"--if you apply $H$ to $\ket{0}$ and then measure in the computational basis, you get a $0$ or $1$ with probability $\frac{1}{2}$ each--but often we want to just apply a Hadamard and not measure, instead using it for interference effects. 

Any operation on a qubit is unitary; conversely, and unitary operator can in principle be realized physically as an operation on a qubit. Note that this lets us define measurements in a basis other than the computational basis. Take any orthonormal basis for the state space--say $\ket{+}, \ket{-}$. Since this is a basis, every qubit is equal to a superposition $a\ket{+} + b\ket{-}$ for some complex numbers $a, b$ with the right norms. What would it mean to measure in the $\ket{+}, \ket{-}$ basis just like we measure in the computational basis? Well, whatever it is, it should give us some indication of a $+$ (with probability $|a|^2$) and some indication of a $-$ (with probability $|b|^2$), and then leave the qubit in the state $\ket{+}$ or $\ket{-}$ accordingly. One way to do this is to apply the unitary operator that changes the basis from the given basis to the computational basis--i.e. that sends $a\ket{+} + b\ket{-}$ to $a\ket{0} + b\ket{1}$--measure in the computational basis, noting a $+$ if we get a $0$ and a $-$ if we get a $1$, and then apply the inverse change of basis, that sends $\ket{0}$ to $\ket{+}$ and $\ket{1}$ to $\ket{-}$. In the specific example of the $\ket{+}, \ket{-}$ basis, the Hadamard gate is a change of basis from the computational basis to the $\ket{+}, \ket{-}$ basis, and it is its own inverse, so it can do the other change of basis as well. Thus to measure in the $\ket{+}, \ket{-}$ basis, we can apply a Hadamard gate (transforming into the computational basis), measure in the computational basis, and then apply another Hadamard gate (transforming out of the computational basis). 

## A Physical Example: Spin and the Stern-Gerlach Experiment
The computational basis and the $+, -$ basis turn out to have a physical interpretation, as representing the spin of an electron. Consider the following experiment: a beam of hydrogen atoms comes from a hot source (which presumably creates atoms in more-or-less randomized states). The beam is then passed through a "Stern-Gerlach apparatus" consisting of some magnets along, say, the z-axis. Skipping over some of the physics, we expect the atoms to be deflected in directions depending on the magnetic moment of the atom, which in turn depends on the angular momentum of the electron. In fact the atoms get deflected into two beams of equal intensity, one "up" and one "down": so it seems as though there is only a discrete set of z-axis magnetic moments that we can measure. 

Say we take the beam that go deflected up, and pass it through another apparatus; then that beam will only get deflected up, suggesting that the original apparatus just filtered the atoms into ones which were already disposed to go up and ones which are already disposed to go down. But this is complicated by the results we get when we add more apparatuses, possibly oriented along other axes. Say we instead pass the beam from the source through an apparatus oriented along the x-axis. Then we'll once again see two beams, one deflected left and one deflected right, and if we pass the right beam through another x-oriented apparatus, it will just get deflected right. But if we pass the beam from the source through a z-oriented apparatus, and then pass the up beam through an x-oriented apparatus, we get two beams. If we then pass the right beam from that through another z-apparatus, we don't get a beam that just goes up (as we would expect if the first apparatus had just filtered for atoms that were already z-oriented up, and they had stayed that way through the x-apparatus): instead we get two beams of equal intensity, just as though we were sending a beam directly from the source into the z-apparatus.

In fact, it turns out that we can account for this by representing the angular momenta of the electrons like qubits. There are two states $\ket{Z+}$ and $\ket{Z-}$, which form an orthonormal basis for the state space, such that an atom whose electron is in the first state will always get deflected up by a z-apparatus, and the same for the other state. An electron can also be in a superposition $a\ket{Z+} + b\ket{Z-}$; in that case, when passing through a z-apparatus, it will go up and end up in the state $\ket{Z+}$ with probability $a^2$ and go down and end up in the state $\ket{Z-}$ with probability $b^2$. There is also another orthonormal basis $\ket{X+}, \ket{X-}$, which plays the same role for deflections right and left in an x-oriented apparatus. Crucially, the z-basis and x-basis are related just like the computational basis and $+, -$ basis for a qubit: we have $\ket{X+} = \frac{\ket{Z+} + \ket{Z-}}{\sqrt{2}}$ and $\ket{X-} = \frac{\ket{Z+} - \ket{Z-}}{\sqrt{2}}$. When we pass an atom through a z-apparatus, we measure in the z-basis and collapse into one of the basis states: hence why an up beam, passed through a z-apparatus, gives just another up beam. But an atom in one of those z-basis states is in a linear combination of the x-basis states with amplitudes of equal magnitude: hence measuring such an atom in the x-basis, by passing it through an x-apparatus, gives you left or right with equal probability. Then it ends up in an x-basis state, which has a similarly wide spread in the z-basis: hence why atoms from an x-apparatus get deflected randomly by a z-apparatus, even if they passed through a z-apparatus before passing through the x-apparatus. 
## Systems of Qubits
We can also have several qubits at once. These could be in a simple, "classical" state like $\ket{0}\ket{0}$, often denoted just $\ket{00}$; or one could be in a superposition, like $(\frac{\ket{0} + \ket{1}}{\sqrt{2}})\ket{0}$, which works out to $\frac{\ket{00}}{\sqrt{2}} + \frac{\ket{10}}{\sqrt{2}}$ (in general we allow ourselves to "distribute out" states like this--all this will be formalized later using tensor products). We can also have multi-qubit states where the state of one qubit cannot be written "independently" from the state of the other (in the sense that the state is $(a\ket{0} + b\ket{1})(c \ket{0} + d\ket{1})$ for suitably sized complex numbers $a, \dots, d$). These are called entangled states. For example we have the "Bell states"
$$\ket{\beta_{00}} = \frac{1}{\sqrt{2}}(\ket{00} + \ket{11})$$
$$\ket{\beta_{01}} = \frac{1}{\sqrt{2}}(\ket{01} + \ket{10})$$
$$\ket{\beta_{10}} = \frac{1}{\sqrt{2}}(\ket{00} - \ket{11})$$
$$\ket{\beta_{11}} = \frac{1}{\sqrt{2}}(\ket{01} - \ket{10})$$
These form an orthonormal basis for the (4-dimensional) state space of a 2-qubit system. The names like $\beta_{00}$ come from a certain procedure, described below, for transforming computational basis states into Bell basis states.

In a system of qubits, we have access to all the usual single-qubit operations (any unitary operator on $\C^2$), and can perform them on any qubit of our choosing. We can also in principle implement any unitary operation (on the $2^n$ dimensional state space for $n$ qubits). Usually, though, we will work with operations of a more restricted type. For example, we might perform a single-qubit operation on some or all of the qubits, e.g. the "Hadamard transform", denoted $H^{\otimes n}$ , applies a Hadamard gate to every qubit, turning a computational basis state $\ket{0\dots0}$ into an equal superposition of all possible computational basis states. We can also work with "controlled operations", which do or don't apply a transformation to some "target" qubits depending on the state of a "control" qubit (usually the "first" qubit in a bit string). For example there is the "controlled-NOT" gate, which applies NOT to the second qubit if the first qubit is $\ket{1}$, and does nothing otherwise. I.e. $\ket{00}$ goes to $\ket{00}$, $\ket{01}$ goes to $\ket{01}$, $\ket{10}$ goes to $\ket{11}$, and $\ket{11}$ goes to $\ket{10}$. More generally, for any unitary $U$, we can have an operator which applies to the second qubits, or the rest of the qubits, if and only if the first qubit is $1$. Such operators will have the block form 

$$\begin{pmatrix} 1 & & \\ & 1 & \\ & & U \end{pmatrix}$$
in the computational basis. 

Since operations have to be unitary (and so reversible), while many classical Boolean operations are not, we cannot implement these directly. Other classic operations are not possible for different reasons: for instance, we can copy bits, we can't copy an arbitrary qubit, per the no-cloning theorem. However, we can implement many of these operations with reversible gates like the Toffoli gate plus "ancilla" qubits; see ADD LINK LATER for more. 

Finally, we define measurements on systems of qubits. We use a 2-qubit system as an example; the generalization should be clear. In a superposition $a\ket{00} + b\ket{01} + c\ket{10} + d\ket{11}$, we can measure the whole system in the computational basis; we get, say, $00$ with probability $|a|^2$, and then collapse into the state $\ket{00}$. Measurements in other orthonormal bases work just like in the single-qubit case: change bases, measure in the computational basis, change back. We can also measure just one of the qubits, in which case it collapses and we end up in a superposition where half of the possibilities have been "killed off". For example, we can measure just the first qubit, getting a $0$ with probability $|a|^2 + |b|^2$. We end up in a superposition of $\ket{00}$ and $\ket{01}$, namely $\frac{1}{\sqrt{|a|^2 + |b|^2}}(a\ket{00} + b\ket{01})$; we normalize to ensure the state vector ends up as a unit vector while, loosely speaking, preserving the phases and relative sizes of the amplitudes of $\ket{00}$ and $\ket{01}$. 
# Quantum Mechanics in General
## State Vector Formalism: Postulates
### Quantum States
The state of a system is represented by a unit vector in some complex Hilbert space. (So in particular there must be some inner product on the space; for finite-dimensional spaces this automatically makes it a Hilbert space, while for infinite-dimensional spaces we need to verify separately that the metric induced by the inner product turns it into a complete metric space.) This postulate alone does not tell you much about what the state vector of a system is, or what sort of state space it lives in. A qubit has a 2-dimensional state space, while a free particle may have an infinite-dimensional state space, in which case we think of the state vector as being a function, the *wavefunction* of the particle.  

The requirement that the state vector be a unit vector makes more sense in the context of measurements. Say for simplicity that we're in a 2-dimensional state space; then we can find an orthonormal basis $\ket{x}, \ket{y}$, in which case any state can be represented as a superposition $a\ket{x} + b\ket{y}$, and the unit-vector condition implies that $|a|^2 + |b|^2 = 1$. It will turn out that we can "measure in the $\ket{x}, \ket{y}$ basis" and get back a result of $x$ with probability $|a|^2$ and $y$ with probability $|b|^2$; thus the unit-vector condition corresponds to the requirement that probabilities sum to 1.
### Evolution of Quantum States
One way of describing how quantum states change over time is with unitary operators: if the state at one time is $\ket{\phi}$, for any later time there exists a unitary operator $U$ such that the state then is $U\ket{\phi}$. All the basic quantum gates are examples of unitary operators on qubits, for instance. 

On the other hand we can describe the evolution in terms of Schrodinger's equation: letting $\ket{\phi}$ be the state of the system, there exists some Hermitian operator associated to the system, the Hamiltonian $H$, such that $ih\frac{d}{dt}\ket{\phi} = H{\ket{\phi}}$, where $h$ is Planck's constant. (Note that since $H$ is Hermitian it can be diagonalized with respect to some orthonormal basis; the vectors in this basis are the energy eigenstates of the system). 

We now show, roughly, that these are equivalent: that the description in terms of the Schrodinger equation gives you the description in terms of unitary operators and vice versa.

First we show that solutions to Schrodinger's equation on a given time interval $[t_1, t_2]$ are unitary operators. Indeed, manipulating the equation into $\frac{d}{dt}\ket{\phi} = \frac{H\ket{\phi}}{hi} = \frac{-i}{h}H\ket{\phi}$, and letting $\ket{\phi(t_1)}$ be the state at $t_1$, it turns out that $e^{(-i/h)H(t - t_1)}\phi(t_1)$ , where that $e$ represents the matrix exponential, is a solution. Thus to get $\ket{\phi(t_2)}$ we apply the operator $e^{(-i/h)H(t_2 - t_1)}$ to $\ket{\phi(t_1)}$. For, if we diagonalize $H$ as $\sum_\lambda \lambda \ket{\lambda}\bra{\lambda}$ where the eigenvectors $\ket{\lambda}$ form an orthonormal basis, and then exponentiate, we get $e^{(-i/h)H(t_2 - t_1)} = \sum_{\lambda} e^{-i(\frac{(t_2 - t_1)\lambda}{h})} \ket{\lambda}\bra{\lambda}$; each of those scalars is $e$ to an imaginary power and so has norm $1$, so this new operator can be diagonalized with respect to an orthonormal basis with all of its eigenvalues having norm $1$, meaning it is a unitary operator. 

Next we show that any unitary operator $U$ has a corresponding hermitian operator $K$ such that $e^{iK} = U$. (This can then serve as part of a solution to the Schrodinger equation.) All we need to do is let $K = -i\log(U)$; then $e^{iK} = e^{(i \cdot -i)\log(U)} = e^{\log(U)} = U$. Of course we should be careful w/r/t whether our manipulations with the matrix exponential and matrix logarithm make sense here. $U$ is unitary, and so is normal, and so can be diagonalized in an orthonormal basis, $U = \sum_\lambda \lambda \ket{\lambda}\bra{\lambda}$. Then $-i\log(U) = -i\sum_\lambda \log(\lambda)\ket{\lambda}\bra{\lambda} = \sum_{\lambda}-i\log(\lambda)\ket{\lambda}\bra{\lambda}$. If we plug this into the complex matrix exponential $e^{iK}$ we get $\sum_{\lambda} e^{i(-i\log(\lambda))}\ket{\lambda}\bra{\lambda} = \sum_\lambda e^{\log(\lambda)}\ket{\lambda}\bra{\lambda} = \sum_\lambda \lambda \ket{\lambda}\bra{\lambda} = U$, as desired. 

### Measurements
The most general form of the measurement postulate is this. For every sort of thing one can measure, there exist a set of *measurement operators* $M_m$, one for each possible measurement outcome $m$. The probability that $m$ is measured on a given state $\ket{\psi}$ is given by $p(m)= \bra{\psi}M^{\dagger}_mM_m\ket{\psi}$ , in other words by the inner product of $M_m\ket{\psi}$ with itself. The state of the system after measurement will be $\frac{M_m\ket{\psi}}{\sqrt{p(m)}}$. A set of measurement operators ought to cover all possible outcomes of a measurement, so we have $\sum_m p(m) = 1$. That is, $\sum_m \bra{\psi}M_m^{\dagger}M_m\ket{\psi} = 1$ for any state $\ket{\psi}$, and it turns out that the only way for this to hold for all unit vectors $\ket{\psi}$ is if the "completeness equation" $\sum_m M_m^{\dagger}M_m = I$ holds. 

#### Projective Measurements
An important special case (which includes the idea of "measuring in an (orthonormal) basis" as a further special case) is that of projective measurements. One way to formulate these: say we have a number of measurement outcomes $1, \dots, m, \dots$ and, associated to each, a subspace $S_m$ of the state space that is orthogonal to all the other $S_n$ with $i \neq m$, and such that the direct sum of all these subspaces is the state space. (That is, we have $P_mP_n = \delta_{mn}P_m$ where $\delta_{mn} = 0$ if $m \neq n$, $\delta_{mn} = 1$ otherwise, and we have $\sum_m P_m = I$.) Then, letting $P_m$ be the projector onto $S_m$, the set of all $P_m$ forms a set of measurement operators (i.e. it satisfies the measurement postulate above). Note that since $P_m$ is an orthogonal projector we have $P_m^\dagger = P_m$ and so $P_m^\dagger P_m = P_m^2 = P_m$; thus the probability of observing $m$ is $\bra{\psi} P_M \ket{\psi}$. If we have an orthonormal basis $\ket{m}$ we can take the set of outer products $\ket{m}\bra{m}$ as our set of projectors; the probability of observing $m$ in a given state $\ket{\psi}$ is then $\bra{\psi}\ket{m}\bra{m}\ket{\psi}=  |\bra{m}\ket{\psi}|^2$, i.e. the square of the absolute value of the amplitude of $\ket{m}$ when writing $\ket{\psi}$ in the $\ket{m}$ basis. 

An alternate formulation of projective measurements is based on the idea of an "observable". Any Hermitian operator can be considered an observable. If $M$ is such an operator, then it is diagonalizable with respect to an orthonormal basis, and all of its eigenvalues are real. Thus we can write $M = \sum_m mP_m$ where the $m$ are eigenvalues of $M$ and the $P_m$ are corresponding orthogonal projectors onto the eigenspaces. Conversely, if we have a set of projective measurements $P_m$ in the sense described above, i.e. with an orthogonal projector $P_m$ corresponding to a measurement outcome $m$, we can get an observable for that set of measurements just by taking $\sum_m mP_m$, and this will be Hermitian because it is diagonalizable in the right way. 
##### Statistics of Projective Measurements
Using observables gives us simple formulas for some important measurement statistics. Let $\{P_m\}$ be a set of orthogonal projectors with associated measurement outcomes $\{m\}$, and let $M$ be the associated observable. Then the expected value of a measurement of this observable on a state $\ket{\psi}$ is $\sum_m mp(m) = \sum_m m\bra{\psi}P_m\ket{\psi} = \sum_m \bra{\psi}mP_m \ket{\psi} = \bra{\psi}(\sum_m mP_m)\ket{\psi} = \bra{\psi}M\ket{\psi}$. Note that the expectation of $M$ in a given state is sometimes written $\langle M \rangle$; this notation suppresses the state $\ket{\psi}$, but remember that it doesn't make sense to talk about "the expectation of $M$" in general, rather the expected value of $M$ *when measuring a particular state* $\ket{\psi}$. 

If $M$ is Hermitian, then so is $M - cI$ for any scalar $c$; in particular $M - \langle M \rangle$ is Hermitian, as is $(M - \langle M \rangle)^2$, since the product of Hermitian operators is Hermitian. Thus $(M - \langle M \rangle)^2$ is an observable; by definition of the variance, its expectation value is the variance of $M$ (of course for a given state $\ket{\psi}$ which we omit from the notation). The expectation of $(M - \langle M \rangle^2)$ is $E(M^2 - 2\langle M \rangle M + \langle M \rangle^2) = E(M^2) - 2\langle M \rangle E(M) + E(\langle M \rangle^2) = \langle M^2 \rangle - 2\langle M \rangle^2 + \langle M \rangle ^2 = \langle M^2 \rangle - \langle M \rangle^2$; thus the standard deviation of $M$, denoted $\Delta M$, is $\sqrt{\langle M^2 \rangle - \langle M \rangle^2}$.  

If $\ket{\psi}$ is an eigenvector of an observable $M$ with eigenvalue $m$, then the mean and standard deviation of $M$ on $\ket{\psi}$ will just be $m$ and $0$. For, letting $M = \sum_k kP_k$ where $P_k$ is the projector onto the eigenspace with eigenvalue $k$, we have $P_m\ket{\psi} = \ket{\psi}$ and $P_k\ket{\psi} = 0$ whenever $k \neq m$; since $M$ is Hermitian, distinct eigenspaces are orthogonal to each other, and so the projection of $\ket{\psi}$ onto another eigenspace is just the zero vector. Then we have $\langle M \rangle = \bra{\psi}\sum_k kP_k \ket{\psi} = \sum_k k(\bra{\psi}P_k\ket{\psi}) = m\bra{\psi}\ket{\psi} = m$; also $M^2 = \sum_k k^2P_k$, so $\langle M^2 \rangle = m^2$, and so $\Delta M = \sqrt{m^2 - m^2} = 0$. 
##### Example: Spin Measurements
The Pauli matrices are all examples of observables; in particular, if we think of the computational basis states $\ket{0}, \ket{1}$ as representing spin up (1) and spin down (-1) along the z-axis, then the $Z$ matrix is an observable for measuring along the z-axis, the $X$ matrix is an observable for measuring along the x axis, and certain linear combinations of the Pauli matrices give observables for measurements along arbitrary axes.Â 

Take for example the $Z$ matrix. Given that a qubit in the state $\ket{0}$ will always give a measurement of $1$ (spin-up) and a qubit in state $\ket{1}$ will always give a measurement of $-1$, we expect that the observable for z-spin measurements will have $\ket{0}$ and $\ket{1}$ as eigenvectors with eigenvalue $1$ and $-1$, and so $Z = \ket{0}\bra{0} - \ket{1}\bra{1}$, which indeed gives $Z = \MatrixTwoTwo{1}{0}{0}{-1}$. 

The same goes for, say, $X$, which ought to be $\ket{+}\bra{+} - \ket{-}\bra{-}$. We can then use this to calculate measurement statistics for x-spin measurements of a qubit in the state $\ket{0}$. In this case we have $\langle X \rangle = \bra{0}(\ket{+}\bra{+} - \ket{-}\bra{-})\ket{0} = \bra{0}\ket{+}\bra{+}\ket{0} - \bra{0}\ket{-}\bra{-}\ket{0}$. Note that $\bra{+}\ket{0} = \frac{1}{\sqrt{2}}(\bra{0}\ket{0} + \bra{1}\ket{0}) = \frac{1}{\sqrt{2}}$, and the same for $\bra{0}\ket{+}$, while $\bra{-}\ket{0} = \frac{-1}{\sqrt{2}}$. Thus the mean is $(\frac{1}{\sqrt{2}})^2 - (\frac{-1}{\sqrt{2}})^2 = 0$. As for the standard deviation, it is $\sqrt{\langle M^2 \rangle - \langle M \rangle^2}$. The second term we already calculated to be $0$. $M^2$ is $(P_+ - P_-)^2$, where $P_+, P_-$ are the projectors onto the $\ket{+}, \ket{-}$ eigenspaces; thus it is $P_+^2 - 2P_+P_- + P_-^2 = P_+ + P_-$. The expectation of this is then just  $\bra{0}\ket{+}\bra{+}\ket{0} + \bra{0}\ket{-}\bra{-}\ket{0} = 1$. Thus measurements of spin along the x-axis in the state $\ket{0}$ have a mean of 0 and a standard deviation of 1. 

More generally, letting $v = (v_1, v_2, v_3)$ be a unit vector in $\R^3$, the observable for measuring spin along the $v$ axis, denoted $v \cdot \sigma$, is $v_1\sigma_1 + v_2\sigma_2 + v_3\sigma_3$. 
##### Projective Measurements and Unitary Operators Give All Measurements

#### POVMs
The general measurement operator formalism tells you, in terms of the measurement operators $M_m$, the probability of each outcome occurring and, for each outcome, the state of the system after that outcome is measured. Note however that the only place where the measurement operators show up on their own is when talking about the state afterward; to know the probabilities, all we need are the operators $M_m^\dagger M_m$. These are positive operators and so are even "nicer" than the more general sorts of operators that can show up in the general measurement postulate. One might hope that it's possible to rephrase the measurement postulate solely in terms of these positive operators, at least if one only cares about the probabilities.

POVMs (positive operator value measurements) make this possible. A POVM is just a set of positive operators $\{E_m\}$ such that the completeness relation $\sum_m E_m = I$ holds; the probability of getting a measurement result $m$ in a state $\ket{\psi}$ is $\bra{\psi}E\ket{\psi}$. 

This is equivalent in a fairly simple way to the general measurement postulate. For, if $\{M_m\}$ is a set of measurement operators, then the set $\{M^\dagger_mM_m\}$ is a POVM, since $M_m^\dagger M_m$ is positive for any operator $M_m$, and the completeness relation and probability rule for POVMs hold because the corresponding facts about general measurements hold. In the special case where we have a set of projective measurements $\{P_m\}$, the corresponding POVM is just $\{P_m\}$: each measurement operator also works as a POVM element (after all $P_m^\dagger = P_m$ and $P_m^2 = P_m$, hence $P_m^\dagger P_m = P_m$). For the other direction, given a set of POVM elements $\{E_m\}$, define a set of measurements $\{M_m\}$ where $M_m$ is the positive square root of $E_m$ (guaranteed to exist since it's a positive operator); these then satisfy all the relevant parts of the general measurement postulate. (Incidentally, we also have a sort of converse of the fact that a set of projective measurements is also a POVM: namely, any set of measurement operators such that each measurement operator $M_m$ equals the corresponding POVM $E_m$ is a set of projective measurements. For of $M_m = E_m$ then $M_m$ is positive, hence self-adjoint. We know by definition of "corresponding POVM" that $E_m = M_m^\dagger M_m$; thus $M_m = M_m^\dagger M_m = M_m^2$ and so each $M_m$ is an orthogonal projector.)

Given that POVMs are so closely equivalent to general measurements, their usefulness
may not be clear, but it is sometimes easier to construct POVM elements for a given purpose than to construct the corresponding measurement operators. See for instance "distinguishing states" below. 
### Combining Systems
Given two systems with state spaces $A$ and $B$, the state space of both of them together is given by the tensor product $A \otimes B$. This means that individual states of the joint system are linear combinations of tensor products $\ket{a}\otimes \ket{b}$ (or just $\ket{a}\ket{b}$, or $\ket{ab}$) of the individual systems. 

The "*linear combinations* of tensor products" part of that description is important; not every state can be written as a tensor of two states from the subsystems. States that cannot be written this way are *entangled*. Take for instance the Bell state $\frac{\ket{00} + \ket{11}}{\sqrt{2}}$. Suppose it is actually a tensor product of two states $(a\ket{0} + b\ket{1})(c \ket{0} + d\ket{1})$. Distributing it all out we get $ac\ket{00} + ad\ket{01} + bc\ket{10} + bd\ket{11}$. Given that the amplitudes on those middle terms should be $0$ to get the Bell state, at least one of $a$ and $d$ should be $0$, as should at least one of $b$ and $c$. But this means that at least one of the amplitudes on $\ket{00}$ and $\ket{11}$ is $0$, so we don't actually get the Bell state.
## Other Aspects
### Distinguishing States
#### Distinguishing Orthonormal States
Suppose you are given a system in state $\ket{\psi}$, which you are told is one state from the orthonormal set $\{\ket{1}, \dots, \ket{n}\}$. Then it is easy to tell which one you have: define the projective measurements $P_m$ by $\ket{m}\bra{m}$, and then another operator $P_0$ as (the positive square root of the operator) $I - \sum_m P_m$. Then this forms a complete set of measurement operators which, if the system is in the state $\ket{m}$, will return the measurement result $m$ with probability $1$. 
#### Impossibility of Distinguishing Non-Orthogonal States
We might however expect that distinguishing more general sorts of states is impossible, given that it would let you communicate faster than light. Suppose Alice and Bob share the Bell state $\frac{\ket{00} + \ket{11}}{\sqrt{2}}$. If Alice measures in the computational basis then Bob's qubit will end up as either $\ket{0}$ or $\ket{1}$. Suppose instead that Alice measures in the $\ket{+}, \ket{-}$ basis. Since (up to a normalization factor) $\ket{0} = \ket{+} + \ket{-}, \ket{1} = \ket{+} - \ket{-}$, the joint state can be written (again up to a normalization factor) $(\ket{+} + \ket{-})(\ket{+} + \ket{-}) + (\ket{+} - \ket{-})(\ket{+} - \ket{-})$ = $\ket{++} + \ket{+-} + \ket{-+} + \ket{--} + \ket{++} - \ket{+-} - \ket{-+} + \ket{--}$  = $2\ket{++} + 2\ket{--}$
When properly normalized this looks just like a Bell state, $\frac{\ket{++} + \ket{--}}{\sqrt{2}}$. So if Alice measures in this basis, Bob will be left with either a $\ket{+}$ or a $\ket{-}$. Thus if Bob can perform a measurement that tells him which of the four states $\ket{0}, \ket{1}, \ket{+}, \ket{-}$ he has, Alice can communicate a bit by choosing to measure in the computational basis or $\ket{+}, \ket{-}$ basis. 


#### Unreliably Distinguishing Linearly Independent States With POVMs

....
More generally, given a set of linearly independent states $\{\ket{1}, \dots, \ket{m}\}$, define $P_i$ to be the projector onto the orthogonal complement of the subspace spanned by $\{\ket{1}, \dots, \ket{m}\} - \{\ket{i}\}$, and then let $E_i = \frac{1}{m+1}P_i$. Since the states are linearly independent, $\ket{i}$ does not lie in the span of the other states, and so projecting it onto the orthogonal complement of their span leaves it nonzero. Thus $\bra{i}E_i\ket{i} \neq 0$, while for any other state $\ket{j}$, $\bra{j}E_i\ket{j} = 0$. To complete the set, define $E_0 = I - \sum_i E_i$. To prove that this is positive, let $\ket{\psi}$ be any vector; we want to show that $\bra{\psi}E_0 \ket{\psi} > 0$. We have $\bra{\psi}E_0 \ket{\psi} = \bra{\psi}\ket{\psi} - \sum_i \bra{\psi}E_i \ket{\psi} = \bra{\psi}\ket{\psi} - \sum_i \frac{1}{m+1}\bra{\psi}P_i \ket{\psi}$. Since $P_i$ is an orthogonal projector, $\bra{\psi}P_i \ket{\psi} \leq \bra{\psi}\ket{\psi}$. Thus $\bra{\psi}E_0 \ket{\psi} \geq \bra{\psi}\ket{\psi} - \sum_i \frac{1}{m+1}\bra{\psi}\ket{\psi} = \bra{\psi}\ket{\psi} - \frac{m}{m +1}\bra{\psi}\ket{\psi} > 0$. 
### The Uncertainty Principle
Quantum measurements are in general probabilistic, but for a given state $\ket{\psi}$, there will generally be measurements that return the same result with certainty--for instance, observables of which $\ket{\psi}$ is an eigenvector. There will also often be observables where measurements have a large spread 
## Density Operators
### Pure and Mixed States
If a system is definitely in some state $\ket{\psi}$--if you know exactly what state it's in, or however else you want to flesh this out--then we say that it's in a pure state. You could also consider a system whose state is drawn from a probability distribution of states: say it'll be in the state $\ket{\psi_i}$ with probability $p_i$. This is called a "mixed state" or an "ensemble of pure states", and it can be represented by the density operator $$\rho = \sum_i p_i \ket{\psi_i}\bra{\psi_i}$$ In the case of a pure state this reduces to a single outer product $\ket{\psi}\bra{\psi}$. All the basic postulates can be restated in terms of density operators. 

Evolution: say you have an ensemble of states $\ket{\psi_i}$ with probabilities $p_i$, giving a density operator $\rho$, and your system evolves by the unitary operator $U$. Then you have an ensemble of states $U\ket{\psi_i}$ with probabilities $p_i$, and the corresponding density operator is $$\sum_i p_i U\ket{\psi_i}\bra{\psi_i}U^\dagger = U(\sum_i p_i\ket{\psi_i}\bra{\psi_i})U^\dagger = U\rho U^\dagger$$ (recall that, when we take the conjugate transpose of $U\ket{\psi}$, $U$ gets turned into $U^\dagger$)

Measurements: let $\{M_m\}$ be a set of measurement operators on the state space. First we want to find the probabilities of each outcome when measuring a mixed state with density operator $\rho = \sum_i p_i \ket{\psi_i}\bra{\psi_i}$. Recall that, for a pure state $\ket{\psi}$, we have $p(m) = \bra{\psi}M^\dagger M \ket{\psi}$; we also have the relation, for any operator $A$, that $\bra{\psi}A\ket{\psi} = \tr(A\ket{\psi}\bra{\psi})$. Thus $p(m) = \tr(M^\dagger M \ket{\psi}\bra{\psi}$), and so $p(m \mid i) = \tr(M^\dagger M \ket{\psi_i}\bra{\psi_i})$, and so $p(m) = \sum_i p(m \mid i)p_i = \sum_i p_i\tr(M^\dagger M \ket{\psi_i}\bra{\psi_i}) = \tr(\sum_i p_i M^\dagger M \ket{\psi_i}\bra{\psi_i}) = \tr(M^\dagger M \sum_i p_i\ket{\psi_i}\bra{\psi_i} = \tr(M^\dagger M \rho)$.

When we measure a mixed state we will, in general, get another mixed state. The density operator of this state can also be computed purely in terms of the measurement operator and density operator of the state before measurement. Recall that, in a state $\ket{\psi_i}$, the state after a measurement outcome $m$, $\ket{\psi_i^m}$, is $\frac{M\ket{\psi_i}}{\sqrt{p(m)}}$; denote by $p(i \mid m)$ the probability that the state is in $\ket{\psi_i^m}$ given that the measurement outcome was $m$. That is, the density operator $\rho_m$ after outcome $m$ will be $\sum_i p(i \mid m) \frac{M\ket{\psi_i^m}\bra{\psi_i^m}M^\dagger}{p(m)}$. Note then that $p(i \mid m) = p(i \cap m)/p(m)$ and $p(i \cap m) = p(m \mid i)p_i$, so that .........


### Density Operators In General
The above looked at density operators mostly in terms of ensembles of states. Now we consider some general properties of density operators and discuss to what extent an underlying ensemble can be inferred from the system's density operator.

#### Characterization of Density Operators
Any density operator is a positive operator with trace $1$; conversely, given any such operator $\rho$, one can find an ensemble of states $\ket{\psi_i}$ with probabilities $p_i$ such that $\rho = \sum_i p_i \ket{\psi_i}\bra{\psi_i}$. 

For one direction, let $\rho = \sum_i p_i \ket{\psi_i}\bra{\psi_i}$. Then $\tr(\rho) = \sum_i p_i \tr(\ket{\psi_i}\bra{\psi_i}) = \sum_i p_i = 1$, with the first equality following by the linearity of the trace and the second following by the fact that projectors onto 1-dimensional subspace have trace $1$.  For the positivity of $\rho$, we need to show that $\bra{\phi}\rho\ket{\phi} \geq 0$ for all vectors $\ket{\phi}$. We get $\ket{\phi}\rho\bra{\phi} = \sum_i p_i (\bra{\phi}\ket{\psi})(\bra{\psi}\ket{\phi})$; note that the first of those inner products is the complex conjugate of the second, hence their product is $|\bra{\phi}\ket{\psi}|^2$ which is nonnegative. Thus the sum as a whole is nonnegative. 

For the other direction, if $\rho$ is a positive operator, then it is Hermitian (hence can be diagonalized in an orthonormal basis as $\sum_i \lambda_i \ket{i}\bra{i}$ where the $\lambda_i$ are real), and since it is positive, those $\lambda_i$ are nonnegative. Furthermore, since $\tr(\rho) = 1$ and $\tr(\rho) = \sum_i \lambda_i$, the eigenvalues are all nonnegative real numbers which sum to $1$, and so can work as probabilities. Thus $\rho$ could represent a mixture of states $\ket{i}$ with probabilities $\lambda_i$. (Note that, in this construction, the states in the ensemble are orthonormal, but not every ensemble is a mixture of orthogonal states. This then hints at the fact, discussed in more detail below, that many ensembles can give rise to the same density operator.)

We also have a more abstract characterization of pure and mixed states: a density operator $\rho$ represents a pure state if and only if $\tr(\rho^2) = 1$; thus if $\tr(\rho^2) \leq 1$ it's a mixed state. 

First we prove that, for any density matrix, $\tr(\rho^2) \leq 1$. Since it's a positive operator with trace $1$, we can diagonalize it as $\operatorname{diag}(\lambda_1, \dots, \lambda_n)$ where $\lambda_1 + \dots + \lambda_n = 1$ and all eigenvalues are nonnegative real numbers. We then have $\rho^2 = \operatorname{diag}(\lambda_1,^2 \dots, \lambda_n^2)$, and $\tr(\rho^2) = \sum_i \lambda_i^2 \leq (\sum_i \lambda_i)^2 = 1$. 

If $\rho$ is a pure state then $\rho = \ket{\psi}\bra{\psi}$ for some unit vector $\ket{\psi}$; as with any projector we have $\rho^2 = \ket{\psi}\bra{\psi} = \rho$, and so $\tr(\rho^2) = \tr(\rho) = 1$. Conversely, if $\rho$ is a mixed state, then its eigenvalues are all strictly less than $1$, hence the inequality $\sum_i \lambda_i^2 \leq 1$ is strict. 

#### Density Operators Do Not Uniquely Determine Ensembles

### Subsystems and the Partial Trace
Say our system consists of two systems $A, B$ with the density operator for the whole system being $\rho^{AB}$. One way to describe each subsystem, say $A$, is by the "reduced density operator" $\rho^A$, defined by $\rho^A = \tr_B(\rho^{AB})$. Here $\tr_B$ is the "partial trace", a linear operator on matrices defined as follows. For tensors of outer products $\ket{a_1}\bra{a_2} \otimes \ket{b_1}\bra{b_2}$ where the $a_i, b_i$ are pure states of $A$ and $B$, we define $\tr_B$ of this to be $\tr(\ket{b_1}\bra{b_2})\ket{a_1}\bra{a_2}$, which is in turn equal to $\bra{b_2}\ket{b_1} \cdot \ket{a_1}\bra{a_2}$. (recalling the formula for the trace of an outer product operator). Then we extend linearly to handle all density matrices, noting that any positive operator can be written as a linear combination of tensors like $\ket{a_1}\bra{a_2} \otimes \ket{b_1}\bra{b_2}$, or in other notation $\ket{a_1b_1}\bra{a_2b_2}$. 

To motivate the partial trace, we first characterize measurements on a subsystem of a composite system. Given a composite system $AB$, let $M$ be an observable on the subsystem $A$, say $M = \sum_m mP_m$ where $P_m$ is the projection onto the eigenspace for eigenvalue $m$. We want to find an operator $\ol{M}$ on the composite system that corresponds to simply performing the measurement $M$ on $A$ while leaving $B$ alone. Then in the state space of the whole composite system, we expect the eigenstates of $\ol{M}$ to be of the form $\ket{m}\ket{\psi}$, where $\ket{m}$ is an eigenvector of $M$ with eigenvalue $m$ and $\ket{\psi}$ is an arbitrary state of $B$. The projector onto this space is then given by $P_m \otimes I_B$, where $I_B$ is the identity operator on the state space of $B$, and so we should have $\ol{M} = \sum_m m(P_m \otimes I_B)$, which is just $M \otimes I_B$. Thus the tensor product of an observable on $A$ and the identity on $B$ represents a measurement of only the $A$ subsystem of $AB$. Now recall that, for an observable $M$, the average value when you measure a system with density operator $\rho$ is $\tr(M\rho)$. Thus the average value of measurements for $\ol{M}$ is $\tr((M \otimes I_B)\rho^{AB})$. Whatever the density matrix $\rho^A$ for subsystem $A$ turns out to be, it ought to give the same average, i.e. we should have $\tr(M\rho^A) = \tr((M \otimes I_B) \rho^{AB})$. Now write $\rho^{AB} = \sum_i c_i \ket{a_{i1}b_{i1}}\bra{b_{i2}a_{i2}}$ (this could be e.g. a spectral decomposition of $\rho^{AB}$ or just writing it in some other basis consisting of outer-product operators). We then have $(M \otimes I_B)\rho^{AB} = \rho^{AB} = \sum_i c_i \ket{Ma_{i1}b_{i1}}\bra{b_{i2}a_{i2}}$. The trace of this is $\sum_i c_i \tr(\ket{Ma_{i1}b_{i1}}\bra{b_{i2}a_{i2}}) = \sum_i c_i  \bra{b_{i2}a_{i2}}\ket{Ma_{i1}b_{i1}} = \sum_i c_i \bra{a_{i2}}M\ket{a_{i1}}\bra{b_{i2}}\ket{b_{i1}}$. Now consider what happens when you take $\tr(M\rho^A)$. We have $\rho^A = \sum_i c_i \bra{b_{i2}}\ket{b_{i1}} \ket{a_{i1}}\bra{a_{i2}}$, and $\tr(M\rho^A) = \sum_i c_i \bra{b_{i2}}\ket{b_{i1}} \tr(M\ket{a_{i1}}\bra{a_{i2}}) = \sum_i c_i \bra{b_{i2}}\ket{b_{i1}} \bra{a_{i2}}M \ket{a_{i1}}$, exactly the same result. 

We now show that the partial trace is the unique function $f$ from density matrices on the state space of $AB$ to density matrices on the state space of $A$ with the right measurement statistics, i.e. with the property that $\tr(Mf(\rho^{AB})) = \tr((M \otimes I_B)\rho^{AB})$ for all $\rho^{AB}$; we will do this by showing that the coefficients of $f(\rho^{AB})$, in a certain basis for the space of all Hermitian operators on the state space of $A$, are uniquely determined by this requirement. Equip this space with the inner product $\langle A, B \rangle = \tr(AB)$ and let $M_i$ be an orthonormal basis with respect to this inner product. Then we have $f(\rho^{AB}) = \sum_i M_i \langle M_i ,f(\rho^{AB}) \rangle  = \sum_i M_i \tr(M_if(\rho^{AB}))$. By the property that is supposed to characterize $f(\rho^{AB})$, though, we have $\tr(M_if\rho^{AB}) = \tr((M_i \otimes I_B)\rho^{AB})$. Thus $f(\rho^{AB}) = \sum_i M_i \tr((M_i \otimes I_B) \rho^{AB})$. This depends only on $\rho^{AB}$ itself, and does not give us any room for different functions $f$ that still satisfy the relevant property. Thus there can be only such $f$, and we know from the discussion above that $f(\rho^{AB}) = \tr_B(\rho^{AB})$ satisfies it. 

#### Examples
If a density operator consists just of a tensor product $\sigma \otimes \rho$ where $\sigma, \rho$ are density operators for two subsystems, then the partial trace for the first subsystem is $\sigma \tr(\rho) = \sigma$ (since $\tr(\rho) = 1$). (Or to write out the details fully, let $\sigma = \sum_i p_i \ket{a_i}\bra{a_i}, \rho = \sum_i q_i \ket{b_i}\bra{b_i}$. Then $\sigma \otimes \rho = \sum_i p_i \ket{a_i}\bra{a_i} \otimes \sum_j q_j \ket{b_j}\bra{b_j} = \sum_{i, j} p_iq_j \ket{a_i}\ket{b_j}\bra{b_j}\bra{a_i}$; if we trace out the $b_j$ we get $\sum_j q_j \sum_i p_i\ket{a_i}\bra{a_i} = \sum_i p_i \ket{a_i}\bra{a_i} = \sigma$. ) 

Along the same lines, say we have a composite of two pure states, $\ket{a}\ket{b}$. Then its density operator is $\ket{a}\ket{b}\bra{b}\bra{a}$, and if we trace out the $b$ subsystem we get just $\ket{a}\bra{a}$, which is also a pure state. 

Of course the partial trace works in more general situations, possibly involving entanglement. Consider for instance the Bell state $\frac{\ket{00} + \ket{11}}{\sqrt{2}}$. Its density operator is $\frac{1}{2}(\ket{00} + \ket{11})(\bra{00} + \bra{11}) = \frac{1}{2}(\ket{00}\bra{00} + \ket{00}\bra{11} + \ket{11}\bra{00} + \ket{11}\bra{11})$. If we take the partial trace to get a density operator for the first qubit, we get $\frac{1}{2}(\ket{0}\bra{0}\tr(\ket{0}\bra{0}) + \ket{0}\bra{1}\tr(\ket{0}\bra{1}) + \ket{1}\bra{0}\tr(\ket{1}\bra{0}) + \ket{1}\bra{1}\tr(\ket{1}\bra{1}))$. Since $\tr(\ket{x}\bra{y}) = \bra{y}\ket{x}$, the orthonormality of $\ket{0}$ and $\ket{1}$ imply that this is just $\frac{1}{2} \ket{0}\bra{0} + \ket{1}\bra{1} = \frac{1}{2}I$. This is a mixed state, since $\tr(\frac{1}{4}I) = \frac{1}{2}$. The same is true if we trace out the second qubit instead. 

