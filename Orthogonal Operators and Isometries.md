$\newcommand{\Z}{\mathbb{Z}}$ 
# Orthogonal Matrices and O_n
A (real) matrix $A$ is orthogonal if $A^tA = I$. This turns out to be equivalent to the statement that $A$'s columns are an orthonormal basis, and to the statement that left multiplication by $A$ preserves inner products. 

Proof: for one direction, let $A$ be such that $A^tA = I$. The $i, j$ entry is the dot product of row $i$ of $A^t$ and column $j$ of $A$, in other words of column $i$ of $A$ and column $j$ of $A$. Since $A^tA = I$, this dot product will be $1$ if $i = j$ (implying that all of the columns have norm $1$) and $0$ otherwise (implying that distinct columns are orthogonal). Thus all the columns have norm $1$ and are orthogonal; that last fact implies that they are linearly independent, and dimension counting then implies that they span the underlying vector space. 

The $n \times n$ orthogonal matrices form a subgroup of $GL_n$, denoted $O_n$, the orthogonal group. That $O_n$ is a subset of $GL_n$ is clear: each orthogonal matrix has an inverse, namely its transpose. That the identity matrix is an element of $O_n$ is also clear. $I^t = I$, so $I^tI = II = I$. For inverses, if $A \in O_n$, then $A^{-1} = A^t \in O_n$, and $A^t$ is orthogonal iff $A$ is orthogonal, so $O_n$ contains inverses of all its elements. Finally, for closure, if $A$ and $B$ are orthogonal, then $AB$ will be orthogonal, since $(AB)^t(AB) = B^tA^tAB = B^t(A^tA)B = B^tB = I$. 

We can also define another subgroup $SO_n$, the orthogonal matrices with determinant $1$, which will in fact be a normal subgroup (since it is the kernel of the determinant homomorphism on $O_n$). 
# Orthogonal Operators
The orthogonal matrices can be abstractly characterized as "orthogonal operators", linear operators which preserve inner products (in the sense that $\langle Tx, Ty \rangle = \langle x, y \rangle$ for all $x, y$). In fact we only have to require that $T$ preserves lengths; the fact that it preserves inner products in general will then follow. Certainly an orthogonal operator preserves lengths: $|Tx|^2 = \langle Tx, Tx \rangle = \langle x, x \rangle = |x|^2$, so $|Tx| = |x|$ for all $x$. For the other direction, suppose $T$ preserves norms (though we'll work instead with the squares of norms). Then for any $x$, $y$, consider $\langle x - y, x - y \rangle$, which equals $\langle T(x - y), T(x - y) \rangle$. Expanding these out we get $\langle x, x \rangle - 2\langle x, y \rangle + \langle y, y \rangle = \langle Tx, Tx \rangle - 2\langle Tx, Ty \rangle + \langle Ty, Ty \rangle$. Subtracting off $\langle x, x \rangle$ (equal to $\langle Tx, Tx \rangle$) and doing the same for $y$, we get $-2\langle x, y \rangle = -2 \langle Tx, Ty \rangle$ or $\langle x, y \rangle = \langle Tx, Ty \rangle$. 

The precise nature of the equivalence between orthogonal matrices and operators is this: an operator $T$ is orthogonal if and only if its matrix w/r/t the standard basis is orthogonal. For one direction, let $T$ be an orthogonal operator. Then, since $\langle e_i, e_j \rangle = \delta_{ij}$, the same should be true for $\langle Te_i, Te_j \rangle$. Thus the $i$th and $j$th columns of $T$ in the standard basis will be orthogonal for distinct $i, j$, and each column will have norm $1$. This then means, by a similar argument as before, that letting $A$ be the matrix w/r/t the standard basis, we have $A^tA = I$. For the other direction, suppose the matrix of $T$ in the standard basis is orthogonal. Then for any $v, w$, $\langle Tv, Tw \rangle$ will equal the dot product of the coordinate vectors of $Tv$ and $Tw$ in the standard basis (or any other orthonormal basis), i.e. $\langle Tv, Tw \rangle = (Tv)^tTw$ (abusing notation a bit to identify $v, w$ with their coordinate vectors and $T$ with its matrix). This then equals $v^tT^tTw = v^tw = \langle v, w \rangle$. Thus $\langle Tv, Tw \rangle = \langle v, w \rangle$. 

# Explicit Description of O_2 and SO_2
$O_2$ and $SO_2$ can be given explicit descriptions. Note first that the determinant of a matrix $A \in O_n$ will have magnitude $1$: $A^tA = I$ implies $\det(A^t)\det(A) = 1$ or $\det(A)^2 = 1$. This means that the determinant is a surjective homomorphism $O_n \to \{\pm 1\}$, with kernel $SO_n$. By the first isomorphism theorem, $O_n / SO_n$ is isomorphic to $\{\pm 1\}$, and there will be two cosets of $SO_n$ in $O_n$. In particular any element in $O_n$ with determinant $-1$ can be written as a product of some element of $SO_n$ times an arbitrary element of $O_n$ with determinant $1$. (we can choose, e.g. a diagonal matrix with all 1s except for a single -1). 

Now we describe $SO_2$ and $O_2$. We first claim that any element $A \in SO_2$ is of the form $$\begin{pmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta \end{pmatrix}$$ and is just a rotation, while the elements of $O_2$ with determinant $-1$ can be written as $$\begin{pmatrix} \cos\theta & \sin\theta \\ \sin\theta & -\cos\theta \end{pmatrix}$$ This is equal to a product of a rotation and a reflection about the x-axis (being the diagonal matrix with $1$ in the upper left entry and $-1$ in the lower right). Geometrically it is a reflection about the line that makes an angle of $\theta/2$ with the x-axis. 

Proof: recall that the columns of an orthogonal matrix are orthonormal. So, letting $A \in O_n$, the first column $(a, c)^t$ will have norm $1$ and so will be of the form $(\cos\theta, \sin\theta)^t$ for some $\theta$. The second column $(b, d)^t$ will also have norm $1$ and be orthogonal to the first. There are only 2 choices for that, the one 90 degrees counterclockwise from the first and the one 90 degrees clockwise from the first. The first choice is $(\cos(\theta + \pi/2), \sin(\theta + \pi/2))^t$ , and the second choice is $(\cos(\theta - \pi/2), \sin(\theta - \pi/2))^t$. But the first is equal to $(-\sin\theta, \cos\theta)^t$, giving our characterization of $SO_2$. Then we already argued for why our characterization of the determinant $-1$ case follows from this, or we could repeat the same analysis. 

Now we try to get our geometric characterization in terms of reflections for the determinant $-1$ case. The characteristic polynomial of a generic matrix of that form is $\lambda^2 - \cos^2\theta - \sin^2\theta = \lambda^2 - 1$, so we have eigenvalues $1, -1$. Letting $v, w$ be eigenvectors with eigenvalues $1$ and $-1$ respectively, we see that $A$ fixes $v$ and reflects $w$, we have a reflection about the line passing through $v$. Now we need to find $v$, in particular taking a unit eigenvector $\cos(a), \sin(a)$. We then solve the system $$\begin{pmatrix} \cos\theta & \sin\theta \\ \sin\theta & -\cos\theta\end{pmatrix}\begin{pmatrix} \cos(a) \\ \sin(a) \end{pmatrix} = \begin{pmatrix} \cos(a) \\ \sin(a) \end{pmatrix}$$ or just $\cos\theta\cos\alpha + \sin\theta\sin\alpha = \cos\alpha, \sin\theta\cos\alpha - \cos\theta\sin\alpha = \sin\alpha$. Recalling the identity $\cos(x + y) = \cos(x)\cos(y) - \sin(x)\sin(y)$ and the equivalent for $\sin$, we get $\cos(\theta - \alpha) = \cos(\alpha)$ which then implies $\alpha = \theta/2$. 
# Explicit Description of SO_3
Now we handle $SO_3$. Define a rotation of $\R^3$ about the origin to be an operator which fixes some unit vector $u$ (called the pole of the rotation) and rotates the plane orthogonal to $u$. The axis of the rotation is the line spanned by $u$. Each rotation can be described completely by its "spin", a pair of its pole $u$ and the angle $\theta$ of counterclockwise rotation in the plane. Of course this won't be unique, as $-u, -\theta$ will also describe the same rotation, but those are the only 2 pole-angle pairs that will describe the given rotation. 

We now prove that any element of $SO_3$ is a rotation of $\R^3$ about some axis; this has the corollary that the product of two rotations (not necessarily about the same axis) is another rotation about some axis. 

First note that any matrix in $SO_3$ has $1$ as an eigenvalue; the unit vectors corresponding to this eigenvalue will be our 2 choices of poles. Letting $A \in SO_3$, we have $\det A = \det A^t = 1$. Note that $1$ is an eigenvalue of and only if $\det(A - I) = 0$, or $\det(A^t)\det(A - I) = 0$, or $\det(A^t(A - I))$ = 0, or $\det(A^tA - A^t) = 0$, or $\det(I - A^t) = 0$, or $\det((I - A^t)) = 0$, or $\det((I - A^t)^t)) = \det(I - A) = -\det(A - I) = 0$. But note from all these manipulations that we have $\det(A - I) = -\det(A - I)$, so it must just be $0$. 

Now we prove one direction, that any $A \in SO_3$ is a rotation. Let $u$ be an eigenvector of $A$ with eigenvalue $1$ and unit length; this will be the pole of the rotation. Then let $P$ be the plane orthogonal to $u$, a 2-dimensional subspace. $P$ will in fact be invariant under $A$; since $A$ preserves dot products we have $\langle Ap, Au \rangle = \langle p, u \rangle = 0$ for any $p \in P$, but since $Au = u$ this means $\langle Ap, u \rangle = 0$, so $Ap$ is orthogonal to $u$, so $Ap$ will still be in the plane orthogonal to $u$. Choose an orthonormal basis $p_1, p_2$ of $P$, so that $u, p_1, p_2$ will be an orthonormal basis of $\R^3$. In this basis, $A$ will become an orthogonal matrix. It will have a $1$ in the upper left corner and a $2 \times 2$ block in the lower right, $A'$, representing the action of $A$ on $P$. Since $A$ preserves dot products, so does $A'$, and so $A'$ (being the matrix of $A$ restricted to $P$ written in an orthonormal basis) will be an orthogonal matrix as well. In fact it will have determinant $1$, else $A$ as a whole would have determinant $-1$. Thus $A'$ is an element of $SO_2$ and so has the form of a rotation with some angle $\theta$. Thus $A$'s action on $\R^3$ is to fix a pole $u$ and rotate the plane orthogonal to $u$ by some angle $\theta$. 

Finally we do the other direction, that any rotation $\rho$ of $\R^3$ (say with spin $(u, \theta)$) is represented by an element of $SO_3$. Extend $u$ to an orthonormal basis of $\R^3$, say $u, v_1, v_2$. In this orthonormal basis we get the same block form as before, with a $1$ in the upper left and a $2 \times 2$ rotation matrix in the lower right (given, by assumption, that $\rho$ rotates the plane orthogonal to $u$ by an angle $\theta$). We can put this in the standard basis by a change of basis matrix whose columns $u, v_1, v_2$ will be orthonormal, i.e. $\rho$ in the standard basis is a product of $3$ orthogonal matrices. Thus $\rho$ in the standard basis is in $O_3$, and we can easily compute its determinant to be $1$, so it is in $SO_3$. 

A corollary of this is that, if $A \in SO_3$, then the trace is equal to $1 + 2\cos\theta$ (by changing basis to one where it has the nice rotation form). We can use this to get the angle of rotation even if we're given $A$ in a form where this isn't obvious. 

# Isometries
An isometry is a rigid motion of space, or any function on $\R^n$ that preserves distances between points. An isometry that maps some figure or set $F$ onto itself is a symmetry of $F$, and these will in general form a group under composition. 

For example, any orthogonal linear operator is an isometry, as is translation by a given vector. The composition of isometries is an isometry. In fact these facts will more or less serve to characterize isometries. First we characterize isometries that fix the origin or preserve dot products as orthogonal linear operators. 

## Which Isometries are Orthogonal Operators?
First we consider isometries that preserve the origin. In fact the following are equivalent: (1) T is an isometry that preserves the origin, (2) T preserves dot products, (3) T is an orthogonal linear operator. We already know (3) -> (1) and (3) -> (2). 

We first prove (1) -> (2). Consider the dot product $(Tu - Tv)\cdot (Tu - Tv) = (u - v)\cdot (u - v)$ (true since $T$ preserves distances). Expanding these out, we get $Tu \cdot Tu - 2(Tu \cdot Tv) + Tv \cdot Tv = |u|^2 - 2(u \cdot v) + |v|^2$. If we consider the special case $u = 0$, we get $|Tv|^2 = |v|^2$ (since $Tu = 0$ as well). Thus $T$ preserves lengths. So, going back to the equation $|Tu|^2 - 2(Tu \cdot Tv) + |Tv|^2 = |u|^2 - 2(u \cdot v) + |v|^2$, we can subtract $|u|^2 (= |Tu|^2)$ and $|v|^2 (=|Tv|^2)$ to get $-2(Tu \cdot Tv) = -2(u \cdot v)$ or $Tu \cdot Tv = u \cdot v$. Thus an isometry fixing the origin preserves dot products. 

Now we show (1) -> (3). We first need the following lemma: that an isometry preserving the origin is completely determined by its action on an orthonormal basis. Suppose $f, f'$ have this property and are such that $f(e_i) = f'(e_i)$ for all vectors $e_i$ in an orthonormal basis $e_1, \dots, e_n$. Then $f = f'$. Proof: suppose $f(0) = f'(0) = 0, f(e_i) = f'(e_i) = h_i$. Then $h_1, \dots, h_n$ must be an orthonormal basis of $\R^n$ (because $f$ and $f'$ preserve dot products). Now we show that $f(v) = f'(v)$ for any $v$. Looking at the projections $f(v) \cdot h_i, f'(v) \cdot h_i$, we get $v \cdot e_i$ in either case (since $h_i = f(e_i) = f'(e_i)$ and $f, f'$ preserve dot products). And we know that $f(v)$ can be expanded in an orthonormal basis using these projections, as $f(v) = \sum (f(v) \cdot h_i)h_i$; since those dot products are the same for $f$ and $f'$, we have $f(v) = f'(v)$. 

With this in mind, let $f$ be an isometry fixing the origin; we want to show that $f \in O_n$. Let $h_i$ again equal $f(e_i)$, and let $A$ be the operator given by the matrix whose columns are the $h_i$. This will certainly be an orthogonal linear operator, it is also an isometry fixing the origin, and its values on the standard basis agree with those of $f$, so by the lemma above, the operator given by $A$ is equal to $f$. Thus $f$ is an orthogonal linear operator. 

## Classification of Isometries
In fact any isometry of $\R^n$ is equal to the composition of an orthogonal operator and a translation, i.e. $f = t_a \circ \phi$ where $\phi$ is an orthogonal operator and $t_a$ is translation by a vector $a$. Proof: let $f(0) = a$; then $t_{-a} \circ f$ fixes the origin and is still an isometry, so fixes the origin. Letting $\phi = t_{-a} \circ f$, we then get $f = t_a \circ \phi$, as desired. 

As a quick corollary of this we know that the set of all isometries on $\R^n$, denotes $M_n$, is a group. Closure and the existence of an identity are already known; as for inverses, the inverse of $t_a \circ \phi$ is $\phi^{-1} \circ t_{-a}$. 

Another corollary is that the subgroup of translations is a normal subgroup of $M_n$. We have a surjective homomorphism $\pi: M_n \to O_n$ that just sends $f = t_a\phi$ to $\phi$. The kernel of $\pi$ is the group of translations, which is isomorphic to $\R^n$ (as an additive group). To show that this is a homomorphism, we need to have $\pi(t_a\phi \circ t_b\phi') = \pi(t_a\phi) \circ \pi(t_b\phi')$. We have $t_a\phi \circ t_b\phi' = t_at_{\phi b}\phi\phi'$, and $\pi$ of this is equal to $\phi \circ \phi' = \pi(\phi)\pi(\phi')$. 

We now move into a finer-grained classification of isometries. First we define orientation; an isometry is orientation-preserving if $\pi(f) \in SO_n$, and orientation-reversing if not. (That is, whether the isometry preserves orientation is determined by the sign of the determinant of its orthogonal operator part.) 

### Classification of Isometries in R^2
Now we focus on $M_2$, the isometries of the plane. This turns out to have a nice description in terms of (infinitely many) generators and relations.

$M_2$ is generated by translations (operators given by $t_a(x_1, x_2) = (x_1, x_2) + (a_1, a_2)$), rotations, and a reflection. Denote a translation by $a$ as $t_a$, a rotation by angle $\theta$ as $\rho_\theta$, and a reflection about the x-axis as $r$. Then any element $f$ of $M_2$ can be expressed as $t_a \circ \rho_\theta$ or $t_a \circ \rho_\theta \circ r$ for some $a, \theta$. This is unique assuming $\theta \in [0, 2\pi)$. Proof: we know that $f = t_a \circ \phi$ for some orthogonal operator $\phi$, and we know that $\phi$ is either a rotation (if it's orientation-preserving) or a composition of a rotation and $r$ (if it's orientation-reversing). 

Now we describe some relations for computation with these generators. We have:

$\rho_\theta t_v = t_{\rho_\theta v}\rho_\theta$ 
$r t_v = t_{rv}r$ 
$r\rho_\theta = \rho_{-\theta}r$ 
$t_at_b = t_{a+b}$ 
$\rho_\theta \rho_\phi = \rho_{\theta + \phi}$ 
$r^2 = I$ 

With all this, we can place isometries into the following classes: the orientation-preserving isometries, translations and rotations around some point (not necessarily the origin); and the orientation-reversing isometries, reflections about some line (not necessarily a line through the origin) and glides (reflection followed by a translation along the same line). 

Note that something like the change of basis formula works for describing isometries of the plane in different coordinate systems: we conjugate by an isometry that takes one coordinate system to another. 
#### The Orientation-Preserving Case
Let $m \in M$ be an orientation-preserving rotation; then $m = t_a\rho_\theta$ where $t$ is translation by a vector $a$ and $\rho$ is a rotation by angle $\theta$. We want to show that $m$ is either a translation or a rotation around some point. If $\theta = 0$ then we're done. Otherwise, we'll look for a coordinate system in which $m$ is just a rotation. 

In particular, we'll look for a change of coordinates consisting of a translation $t_b$, so that $m' = t^{-1}_bt_a\rho_\theta t_b = t_{-b}t_a\rho_\theta t_b$ is a rotation. In fact this reduces down to $t_{-b}t_at_{\rho b}\rho_\theta = t_{-b + a + \rho b}\rho_\theta$. So, we're looking for a vector $b$ such that $a - b + \rho_\theta(b) = 0$. 

To see whether we can solve this, rewrite as $(I - \rho_\theta)b = a$ . The determinant there is $(1 - \cos\theta)^2 + \sin^2\theta = 1 - 2\cos\theta + \cos^2\theta + \sin^2\theta = 2 - 2\cos\theta$, which is zero as long as $\theta$ is zero (which we assumed going in). Thus we can find the relevant change of coordinates; $m$ will then by a rotation around $b$. 

#### The Orientation-Reversing Case
In this case, we have $m = t_a\rho_\theta r$. Recall that $\rho_\theta r$ is a reflection about the line through the origin making angle $\theta/2$ with the x-axis. We now look for a change of coordinates by rotation, not translation, so that $m' = \rho_{-\alpha} t_a\rho_\theta r \rho_\alpha$ looks nice. Setting $\alpha = \theta/2$ works: we get 

## Finite Subgroups of O_2 and M_2
Let $G$ be a finite subgroup of $O_2$; then either $G$ is isomorphic to $C_n$, with the generator being a rotation by an angle $2\pi/n$, or $G$ is isomorphic to the "dihedral group" $D_n$, generated by a rotation $x = \rho_{2\pi/n}$ and the reflection $y = r$. 

### The Dihedral Group
We can describe the dihedral group $D_n$ abstractly as being generated by two elements $x, y$ subject to the following relations: $x^n = 1, y^2 = 1, yx = x^{-1}y$; or geometrically, as the symmetries of a regular $n$-gon. 
### Discrete Subgroups of R
Before we move on, we'll need a lemma about so-called "discrete subgroups of $\R^+$". These are subgroups such that there exists some $\epsilon > 0$ such that, for all nonzero elements $x$ in the subgroup, $|x| \geq \epsilon$. It turns out that these are equal either to $\{0\}$ or to $\mathbb{Z}\lambda$ for some positive real $\lambda$. Proof: let $G$ be a discrete subgroup and suppose it is not the trivial subgroup. Take two distinct elements $x, y$; then $|x - y| \in G$, by closure and existence of inverses, and $|x - y| \geq \epsilon$ by discreteness. Thus all elements are separated by distance at least $\epsilon$. A consequence of this is that each interval contains only finitely many elements of $G$. Take an arbitrary interval around $0$ that contains some positive elements of $G$ (which must exist, as if $G$ contains only negative numbers it wouldn't be a subgroup) and let $\lambda$ be the smallest positive one, which will then be the smallest positive element of $G$. Now we show that all elements of $G$ are integer multiples of $\lambda$. Take an arbitrary positive element $a \in G$ (once we've handled all the positives, we'll know all the negatives as well); then $a = n\lambda + r$ where $n$ is an integer, $r$ is a nonnegative real number less than $\lambda$. Then $r$ must be in $G$ since $r = a - n\lambda$, but $\lambda$ is the smallest positive element of $G$, so $r$ must not be positive and so must be $0$. Thus $a = n\lambda$, and so any element of $G$ is an integer multiple of the smallest positive element of $G$. 

### Classification of Finite Subgroups of O_2
Every element of $O_2$ is a rotation or a reflection, so we can consider two cases: our finite subgroup $G$ contains only rotations, or contains at least one reflection.

Rotations only: then $G$ contains only finitely many rotations, one of which must be the identity. Let $\Gamma \subseteq \R$ be the subset of angles of a rotation in $G$, i.e. the set of $\theta$ such that $\rho_\theta \in G$. We include repeats, e.g. $0, 2\pi, 4\pi, \dots$ for the identity rotation. This will be a subgroup of $\R^+$, and it will be discrete, since all of the nonzero angles have absolute value at least the absolute value of the smallest angle in $\Gamma$. Its generator must be somewhere in $[0, 2\pi)$, but $\Gamma$ includes $2\pi$, so we have $2\pi = n\lambda$ where $\lambda$ is the generator. Thus $\lambda = \frac{2\pi}{n}$, and so $G$ is the cyclic group of order $n$ generated by $\rho_{2\pi/n}$. 

At least one reflection: rotate the coordinate system so that this reflection is the reflection $r$ about the $x$-axis. Now consider the subgroup $H$ of $G$ containing all the rotations in $G$; this will be isomorphic to $C_n$, by the above, and so consists of multiples of $\rho_{2\pi/n}$ for some $n$. $G$ as a whole must then consist of elements $(\rho_{2\pi/n})^i$ and $(\rho_{2\pi/n})^ir$. Thus $G$ contains the dihedral group $D_n$. Now we show that in fact every element of $G$ is in $D_n$. Let $g \in G$; then $g = \rho_\theta r$ for some $\theta$, and so $\rho_\theta = gr$ must be in $G$. We already found that the only possible angles here are the multiples of $2\pi/n$. Thus $g$ must be one of the elements already listed, and so $g \in D_n$. 

### Classification of Finite Subgroups of M_2
We now move from origin-fixing isometries to general isometries. These turn out to once again by isomorphic to $C_n$ or $D_n$, but we may need to translate coordinates as well as rotate them to get the isomorphism we want. 

We'll need this lemma: for any finite subgroup $G$ of $M_2$, there exists a point $p$ which is fixed by all of the isometries, i.e. $g(p) = p$ for all $g \in G$. Once we have this, we can just choose a coordinate system with $p$ at the origin; then $G$ will consist only of isometries that fix the origin, so will be a finite subgroup of $O_2$, so will be isomorphic to $C_n$ or $D_n$. 

Now we prove this lemma, an example of a "fixed-point theorem". Let $s$ be an arbitrary point in the plane, and consider the "orbit of $s$ under $G$": the set of all $s'$ with $g(s) = s'$ for some $g \in G$. This is denoted $\mathcal{O}_s$. The fixed point will turn out to be the centroid of this orbit (regardless of what $s$ we chose), defined to be equal to $\frac{1}{n}(s_1 + \dots + s_n)$ where $s_1, \dots s_n$ are the elements of the orbit of $s$. 

We now need a second lemma: that isometries carry centroids to centroids, i.e. if $c$ is the centroid of $s_1, \dots, s_n$ and $g$ is an isometry then $g(c)$ is the centroid of $g(s_1), \dots, g(s_n)$. Proof: if $g$ is a translation by $a$, then $\frac{1}{n}(g(s_1) + \dots + g(s_n)) = \frac{1}{n}(s_1 + a + \dots + s_n + a) = \frac{1}{n}(s_1 + \dots + s_n + na) = \frac{1}{n}(s_1 + \dots + s_n) + a$. Thus the centroid of the translated points is the translation of the centroid. If $g$ is a linear operator, then $\frac{1}{n}(g(s_1) + \dots + g(s_n)) = \frac{1}{n}g(s_1 + \dots + s_n) = g(\frac{1}{n}(s_1 + \dots + s_n))$. Any isometry of the plane is a composition of a translation and linear operator, so any isometry carries centroids to centroids.

Now we go back to the proof of the fixed point theorem. For any orbit $\mathcal{O}_s$, each $g \in G$ sends $\mathcal{O}_s$ to itself, i.e. permutes the points of $\mathcal{O}_s$. Thus each $g$ sends the centroid of $\mathcal{O}_s$ to the centroid of $\mathcal{O}_s$, i.e. sends the centroid to itself. Thus this centroid is a fixed point of all the elements of $g$. This proves the fixed point theorem, and by the argument above, allows us to classify all finite subgroups of $M_2$ as isomorphic to $C_n$ or $D_n$. 

## Discrete Subgroups of M_2
Now we look at possibly infinite but "discrete" subgroups of $M_2$: subgroups $G$ where there exist a number $\epsilon$ such that, for any nonzero translation $t_a$ in $G$, $|a| \geq \epsilon$, and for any nonzero rotation in $G$ with angle $\theta$, we have $|\theta| \geq \epsilon$. 

We do this by looking at certain groups related to our discrete subgroup $G$. The translation group $L \subseteq \R^2$ of $G$ is the set of vectors $a$ such that $t_a \in G$. This is in fact a subgroup of the additive group of $\R^2$: the identity ($t_0$) is in $G$, so $0$ is in $L$; whenever $t_a, t_b \in G$ ($a, b \in L$) we have $t_at_b = t_{a+b} \in G$ (so $a+b \in L$); and the same for inverses. 

$L$ is a discrete subgroup of $\R^2$, in the sense that the same condition on norms (there exists $\epsilon > 0$ with $|a| \geq \epsilon$ for all nonzero $a$) holds for $L$. Just as with the classification of discrete subgroups of $\R$ earlier, these can be classified: $L$ is either the trivial group, equal to $\mathbb{Z}a$ for some vector $a$ (integer multiples of $a$), or equal to $\mathbb{Z}a + \mathbb{Z}b$ for some vectors $a, b$. (That last type is called a "lattice".)

The other main group we need to look at is the "point group" $\overline{G}$ of $G$. This is the range of the homomorphism $G \to O_2$ given by $t_a\phi \to \phi$ where $\phi$ is the orthogonal-operator part of $G$. If $G$ is discrete, its point group will be finite, and so will be isomorphic to $C_n$ or $D_n$. (This just follows from the corresponding additive group of angles being discrete, and so the set of angles in $\overline{G}$ that are in $[0, 2\pi]$ is finite.)

Finally, we can put these two together to get the "crystallographic restriction". The first key idea here is that the point group on the translation group, in the sense that if $a \in L, \phi \in \overline{G}$ then $\phi(a) \in L$. Thus any element of the point group is a symmetry of the translation group, in the sense of mapping it to itself. To prove this, we need to show that if $t_a \in G, \phi \in \overline{G}$, then $t_{\phi a} \in G$. Note that $\phi$ may not itself be an element of $G$, but because it is in $\overline{G}$, there must be some $b$ with $t_b\phi \in G$. Let $g$ be this product. We'll show that conjugating $t_a$ by $g$ gets us $t_{\phi a}$, which thus must be in $G$. This is because $gt_a g^{-1} = (t_b\phi)t_a (\phi^{-1}t_{-b}) = t_b t_{\phi a}\phi \phi^{-1} t_{-b} = t_b t_{\phi a} t_{-b} = t_{\phi a}$. 

We have an unusual structure here: elements of $G$ can be thought of as pairs of elements of $L$ and $\overline{G}$, but they multiply differently: $(l, \phi) \cdot (l', \phi') = (l + \phi(l'), \phi\phi')$ (whereas, if this was an ordinary product, we would expect the left component to be $l + l'$). This kind of structure is called a semidirect product and shows up when one subgroup is acting on another. 

This actually gets us something big, with a bit of extra work: if $L$ is nontrivial, the point group must be one of $C_n$ or $D_n$ (which we already knew), but in fact $n$ must be one of $1, 2, 3, 4, 6$ (not $5$). (If $L$ is trivial, then $G$ as a whole is just a finite subgroup of $O_2$ and so can be $C_n$ or $D_n$ for any $n$). Let $a$ be a minimal-length vector in $L$, and take a rotation $\phi$ in $\overline{G}$. We know $a, \phi(a) \in L$, and so the vector going from the tip of one to the tip of the other, $\phi(a) - a$, will be in $L$. But this new vector can't have length smaller than $a$, which rules out angles which are "too small". Letting $l$ be the length of $a$, $l'$ be the length of $\phi(a) - a$, we need to have $l' \geq l$. When this inequality is an equality, the triangle formed by $a, \phi(a), \phi(a) - a$ is equilateral, and so the angle is equal to $\pi/3$, and so $n = 6$. Larger angles give us the natural numbers less than $6$ a possibilities. In all cases except $5$ we can construct such a symmetry; in the $n = 5$ case there's another argument that will rule it out. 

