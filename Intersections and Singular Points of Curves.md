# The Intuitive Idea of Intersection Multiplicity
## Root Multiplicity and Secant Lines
We first consider polynomials in one variable and define the multiplicity of a root. If $p$ is a polynomial with $r$ as a root, then we can factor $p$ as $(x - r)^a q(x)$ where $q$ is a polynomial of degree $\deg(p) - a$ and $(x - r)$ does not divide $q$. We say that $r$ is a root of multiplicity $a$. We may observe that, when $a = 1$, $p$ passes "straight through" the x-axis at $r$, but when $a = 2$, $p$ is tangent to the x-axis. 

Another way of thinking of this situation is to consider the intersection of $p$ with a line $l$ that approaches the x-axis. For example, let $p = x^2$, and consider the line $l = tx$ passing through the origin. This will generally intersect $p$ in two different places: $x = 0$ and $x = t$. As $t$ goes to $0$, these two intersections get closer together, and when $t = 0$ they "merge" into a single intersection. We can therefore think of roots like this as "limits" of two intersections, and say that they count as two roots of $p$. This fits with the algebraic situation, where $x$ divides $p$ twice. Also, since $l$ is just the secant line passing through $p$ at $x=0$, and its limit as $t \to 0$ is the tangent line, this shows that the derivative of $p$ is $0$ at the double root.

More generally, letting $p = x^n$ and $l = tx$, we see that $p$ intersects $l$ at $n$ values of $x$, for a given nonzero value of $t$. These are $x = 0$ and $x = t \cdot \zeta_{n-1}^i$, where $0 \leq i < n-1$ and $\zeta_{n-1}$ is an $n-1$-th root of unity. As $t \to 0$ these merge into a single intersection at $x = 0$. 

The same arguments work for any root of multiplicity $n$. If we can factor $p$ as $(x - r)^n q(x)$, then near $r$, we have $p \approx C(x - r)^n$ for some constant $C$. By translating coordinates we can change this to $Cx^n$, and then show that a line passing through $(0, 0)$ will intersect $p$ in $n$ different points near $0$, with those intersections merging into a single intersection as the slope of the line goes to $0$. 
## Root Multiplicity and Derivatives
The above arguments suggested that, if $r$ is a root of multiplicity $n$, then the first $n-1$ derivatives of $p$ should be $0$. To prove this, we first consider the case of a double root. Let $p = (x - r)q(x)$ where $(x - r)$ may or may not divide $q$. Then $p' = q(x) + (x - r)q'(x)$. If $q$ has $r$ as a root then $p'(r) = q(r) + (r - r)q'(r) = 0 + 0 = 0$; conversely, if $p'(r) = 0$ then $0 = p'(r) = q(r) + 0q'(r) = q(r)$. Thus $r$ is a root of multiplicity $2$ if and only if $p'(r) = 0$. 

Similarly, if $r$ has multiplicity $3$, then $r$ is a double root of $q$. We have $p'' = q' + q' + (x - r)q'' = 2q' + (x - r)q''$; by our proof of the $n=2$ case, we have $q'(r) = 0$, so $p''(r) = 0$. 

Continuing inductively, we get $p^{(n-1)} = nq^{(n-2)} + (x - r)q^{(n-1)}$. If $r$ is a root of $p$ with multiplicity $n$, then it is a root of $q$ with multiplicity $n-1$, so by the induction hypothesis $q^{(n-2)}(r) = 0$. Thus $p^{(n-1)}(0) = 0$ as well. 

Note that the argument above holds for polynomials over any field, not just $\R$, since we can use the [[Galois Theory#Separability and the Formal Derivative|formal derivative]] even for fields besides $\R$ where the ordinary derivative isn't defined. 
```desmos-graph
y = x
y = (x - 2.5)^2
y = (x - 5)^3
(0, 0)|label: multiplicity 1
(2.5, 0)|label: multiplicity 2
(5, 0)|label: multiplicity 3
```


# Algebraic Definition of Intersection Multiplicity
We define the intersection multiplicity $\mu_p(f, g)$ of two curves $f, g$ at a point $p$ to be the dimension (as a vector space over $K$) of $\mathcal{O}_p / (f, g)$, i.e. the dimension of the quotient of the [[Affine Algebraic Curves#The Local Ring|local ring]] at $p$ by the ideal generated by $f$ and $g$.
## Invariance Under Affine Transformations
Let $T$ be an affine transformation defined by $T(x) = Ax + b$, where $A$ is an invertible $2 \times 2$ matrix and $b$ is a vector in $\A^2$. Then $T$ transforms $x$ into $ax + by + c$ for some $a, b, c$, and the same for $y$. Substitutions like this send rational functions to rational functions; if $T(p) = p'$, then rational functions which are well-defined at $p$ get sent to rational functions which are well-defined at $p'$. Thus $T$ is a map, and indeed a homomorphism, from $\mathcal{O}_p$ to $\mathcal{O}_{p'}$. As long as $A$ is nonsingular it will be an isomorphism. It then induces an isomorphism from $\mathcal{O}_p / (f, g)$ to $\mathcal{O}_{p'} / (T(f), T(g))$. Thus they have the same dimension, and so the intersection multiplicity is invariant under affine coordinate transformations. 
## Special Values of $\mu_p$
$\mu_p(f, g)$ can be anywhere from $0$ (in the case where $f, g$ do not actually meet at $p$) to infinity (in the case where $f, g$ have a common component at $p$). In fact, $0 < \mu_p < \infty$ if and only if $f, g$ meet at $p$ but do not have a common component there. Furthermore, $\mu_p = 1$ if and only if $(f, g) = I_p$, the unique maximal ideal in $\mathcal{O}_p$, consisting of all elements whose numerator is $0$ at $p$.
### Multiplicity 0
Proof: if $f, g$ do not intersect at $p$ then $f(p) \neq 0$ and/or $g(p) \neq 0$; say, without loss of generality, $f(p) \neq 0$. Then $\frac{1}{f} \in \mathcal{O}_p$, so $f$ is a unit in $\mathcal{O}_p$, so $(f, g) = (1) = \mathcal{O}_p$ and $\mathcal{O}_p / (f, g)$ is the trivial ring, which has dimension $0$ over $K$. Conversely, if $f(p) = 0$ and $g(p) = 0$, any linear combination of $f$ and $g$ will also equal $0$ at $p$, and thus will not be a unit in $\mathcal{O}_p$. Thus $(f, g)$ is not the unit ideal, and so $\mathcal{O}_p/(f, g)$ is nontrivial, with dimension greater than $0$.
### Infinite Multiplicity
Now, assume that $f, g$ intersect at $p$; for simplicity, translate coordinates so that $p = 0$. We will show that $\mathcal{O}_p/(f, g)$ is finite-dimensional if and only if $f, g$ have no common component passing through the origin. 

Suppose first that they have no common component through the origin. Then we can get rid of any common components that don't pass through the origin: if there exists some polynomial $p$ with $p \mid f, p \mid g$, and $p(0, 0) \neq 0$, then $\frac{1}{p} \in \mathcal{O}_0$, and so $f/p, g/p \in (f, g)$. By abuse of notation we let $f, g$ be what is left after dividing all common components from $f$ and $g$. Now $f$ and $g$ have no common component, so we can use the strategy from [[Affine Algebraic Curves#Curves are infinite, intersections are finite|this proof]] to get an element $p(x) \in K[x]$ which is in $(f, g)$, and similarly $q(y) \in K[y]$ which is also in $(f, g)$. $p$ must pass through the origin, so $p(0) = 0$, and so some power of $x$ divides $p$; let $m$ be the largest such power. Then $p = x^m a(x)$ where $a(0) \neq 0$; thus $1/a \in \mathcal{O}_0$ and so $p/a = x^m \in (f, g)$. Thus when we quotient by $(f, g)$ we kill off $x^m$, and so $x$ is nilpotent in $\mathcal{O}_0 / (f, g)$. The same goes for $y$. This puts an upper bound on the degree of the polynomials that can appear as numerators or denominators in $\mathcal{O}_0/(f, g)$. 

We can then also get that each element of the quotient can be represented by a polynomial. All we need to check is that elements of the form $\frac{1}{p}$ can be so represented. If $p$ shows up as a denominator then it must have a nonzero constant term. In that case $\frac{1}{p}$ can be represented as a formal power series in $x$ and $y$; but the fact that $x, y$ are nilpotent means that all but finitely many terms of the series are $0$. Thus $\frac{1}{p}$ is equivalent to a polynomial. 

Putting these together, we get that every element of $\mathcal{O}_0(f, g)$ can be represented by an element of $K[x, y]$ with degree at most $m + n$, for some integers $m, n$; thus $K[x, y]$ is finite-dimensional, with dimension at most $m + n$. 

Conversely, suppose that $f, g$ do have a common component $d$ with $d(0, 0) = 0$. As before, we can divide out common components that don't pass through the origin, so that $f, g$ consist only of components that pass through the origin, and $\gcd(f, g) = d$. Then $(f, g) \subseteq (d)$. Now let $p$ be a curve passing through the origin which has no component in common with $d$. We will show that the set of polynomials of the form $p^n$ is linearly independent over $K$ in $\mathcal{O}_0$, and so that there exists an infinite linearly independent set in $\mathcal{O}_0 / (f, g)$. Suppose there exist $a_i \in K$, not all zero, with $a_0 + a_1p + \dots + a_np^n = 0$, and let $n$ be the least integer for which this is true. Then, since $p(0, 0) = 0$, evaluating both sides at the origin gets $a_0 = 0$. Thus $p(a_1 + \dots + a_np^{n-1}) = 0$, meaning that (considering $p$ as an element of $K[x, y]$) we have that $p(a_1 + \dots + a_np^{n-1})$ is divisible by $d$. Since $p, d$ have no common factor (we may assume without loss of generality that $p$ has no component which does not pass through the origin), this implies that $a_1 + \dots + a_np^{n-1}$ is divisible by $d$, and not all of the $a_i$ are zero, contradicting the minimality we assumed earlier.

### Multiplicity 1
Intersections of multiplicity $1$ are called "transverse intersections". Intuitively speaking, if two curves intersect at a point where a) they both look locally like straight lines, and b) they aren't tangent to each other in any way, we get a transverse intersection.

One criterion for $f, g$ to intersect transversely at $p$ is that the ideal $(f, g) \subseteq \mathcal{O}_p$ is equal to the unique maximal ideal in $\mathcal{O}_p$, the ideal of functions $f/g$ with $f(p) = 0$, denoted $I_p$. If $(f, g) = I_p$, then $(f, g)$ is equal to the kernel of the evaluation map $\mathcal{O}_p \to K$ that maps $f/g$ to $f(p)/g(p)$. Thus by the first isomorphism theorem, we have that $\mathcal{O}_p/(f, g)$ is isomorphic to $K$, so it has dimension $1$ over $K$, and so $\mu_p(f, g) = \dim(\mathcal{O}_p/(f, g)) = 1$. Conversely, if $\mu_p(f, g) = 1$, then $\mathcal{O}_p/(f, g)$ is isomorphic to $K$, so $(f, g)$ is the kernel of the evaluation map and so is equal to $I_p$.

Another criterion uses the notions of [[Intersections and Singular Points of Curves#Smooth and Singular Points|smooth points and tangents]] developed below: $\mu_p(f, g) = 1$ if and only if $p$ is a smooth point of $f, g$ and the unique tangents of $f$ and $g$ (denoted $T_pf, T_pg$) are distinct. ........
## Additivity
For any curves $f, g, h$ we have that $\mu_p(f, gh) = \mu_p(f, g) + \mu_p(f, h)$. If $f, g$ have a component in common, then by [[Intersections and Singular Points of Curves#Infinite Multiplicity]], both sides of the equation are infinite. Otherwise, we can prove that they are equal by showing that the following:

$$0 \to \mathcal{O}_p/(f, h) \to^{L_g} \mathcal{O}_p/(f, gh) \to^\pi \mathcal{O}_p/(f, g) \to 0$$ is a short [[Cochain Complexes and Exact Sequences#Exact Sequences|exact sequence]]. In that case, a result from the linked article (the alternating sum of the dimensions of the spaces in an exact sequence is $0$) implies $0 = \mu_p(f, g) - \mu_p(f, gh) + \mu_p(f, h)$ or $\mu_p(f, gh) = \mu_p(f, g) + \mu_p(f, h)$, as desired. Here $L_g$ is left multiplication by $g$ and $\pi$ is the projection/quotient map from $\mathcal{O}_p/(f, gh)$ to $(\mathcal{O}_p/(f, gh)) / (g) =\mathcal{O}_p/(f, g)$. 

We need to show that $L_g$ is injective, $\im(L_g) = \ker(\pi)$, and $\pi$ is surjective. The last of those statements is a standard property of quotient maps. For the second, we have $\im(L_g) = (g)$, which is equal to the kernel of the quotient map $\pi$. 

For the first statement, recall that we are already assuming that $f, g$ have no common component through $p$, and by reasoning that we have used previously, we can therefore assume (in $\mathcal{O}_p$) that they have no common component anywhere. Now let $p/q \in \mathcal{O}_p/(f, h)$ be in the kernel of $L_g$, so that (in $K(x, y)$) we have $\frac{p}{q}g = \frac{p'}{q'}f + \frac{p''}{q''}gh$ (i.e. multiplying $\frac{p}{q}$ by $g$ gets us something which is sent to $0$ when we quotient by $(f, gh)$). By clearing denominators and abusing notation a bit we can get $pg = p'f + p''gh$. The left-hand side is divisible by $g$, as is $p''gh$, so $p'f$ must be divisible by $g$ as well. This can only happen if $p'$ is divisible by $g$, since we assumed that $f, g$ have no common component. Returning to the equation $pg = p'f + p''gh$, we can write $p' = rg$ and get $pg = rgf + p''gh$, so $p = rf + p''h$. Thus $p \in (f, h)$, and so it goes to $0$ in $\mathcal{O}_p/(f, h)$. But this then means that our element $\frac{p}{q} \in \ker(L_g)$ is $0$ (as an element of $\mathcal{O}_p/(f, h)$). Thus $\ker(L_g)$ is trivial and so $L_g$ is injective. 
## Multiplicity of Roots
Now we show that, in the case of a single-variable polynomial's intersection with the x-axis, our definition of intersection multiplicity lines up with the usual definition of the multiplicity of a root (the largest power of $(x - r)$ that divides a one-variable polynomial $f(x)$). We will, without loss of generality, look at roots of $0$. Let $f$ be our polynomial, so that its graph is the zero locus of $y - f(x)$; the x-axis is given by $y = 0$. Thus we want to compute $\mu_0(y, y - f(x)) = \dim(\mathcal{O}_0 / (y, y - f(x))$. 

Note first that $\mu_0(y, x^n) = n$. This is because, in $\mathcal{O}_0/(y, x^n)$, quotienting by $y$ removes all terms containing $y$, quotienting by $x^n$ removes all terms of degree at least $n$, and so we are left with a space which has $1, x, \dots, x^{n-1}$ as a basis, and therefore has dimension $n$. Note also that, if $f(x)$ has a nonzero constant term, and so does not pass through the origin, then $\mu_0(y, f(x)) = 0$, by our results above.

Now, the ideal $(y, y - f(x))$ is equal to $(y, -f(x))$, which is in turn equal to $(y, f(x))$. Let $x^m$ be the largest power of $x$ that divides $f(x)$, say $f(x) = x^m g(x)$ where $g(x)$ is not divisible by $x$ and so has a nonzero constant term. Then by additivity, $\mu_0(y, x^m g(x)) = \mu_0(y, x^m) + \mu_0(y, g(x)) = m + 0 = m$, as desired. 

More generally, if $f(x, y)$ is any curve passing through the origin (not necessarily expressible as a one-variable polynomial), then the same result holds. By the same strategy as above (subtracting $y$, or multiples of $y$, from $f$) we can remove any terms divisible by $y$ from $f$, and end up replacing $f(x, y)$ with $f(x, 0$). This is nonzero (as long as $f$ itself is not divisible by $y$) and divisible by $x$ (since $f(0, 0) = 0$ by assumption). Thus we can write $f(x, 0) = x^m g(x)$ as before, where $g(0) \neq 0$, and then compute $\mu_0(y, f) = \mu_0(y, x^mg(x)) = \mu_0(y, x^m) + \mu_0(y, g) = m + 0 = m$. 
## Computing Intersection Multiplicity
Now we show an algorithm for computing $\mu_p(f, g)$ for any curves $f, g$. The idea is to reduce this problem (using additivity and other properties of multiplicity) to some known cases like the multiplicity of an intersection with the $y$-axis, or the intersection multiplicity when the two curves don't intersect at the given point. 

First, we can compute a polynomial GCD to find common components of $f, g$. If a common component through $p$ is discovered, we return $\mu_p(f, g) = \infty$. 

Otherwise, we translate coordinates to shift $p$ to $0$. Then we fall into one of 3 cases.

(1) If $f$ or $g$ do not pass through the origin, we can return $\mu_0(f, g) = 0$.

(2) We can get rid of terms that depend only on $x$. $f$ and $g$ cannot both be divisible by $y$, since they have no common component through the origin. Suppose that neither of them is divisible by $y$; then they both have a term which is just a power of $x$, say $f = ax^m + r_1(x, y)$ and $g = bx^n + r_2(x, y)$, where $r_1, r_2$ contain either products of $x$ and $y$, pure $y$-terms, or pure $x$-terms whose exponent is less than $m$ (for $f$) or $n$ (for $g$). Without loss of generality suppose $m \leq n$. Then $g - \frac{a}{b}x^{n - m}f = bx^n - bx^n - \frac{a}{b}x^{n-m}r_1 + r_2 =- \frac{a}{b}x^{n-m}r_1 + r_2$. Thus we have killed off the $x^n$ term in $g$, and the only pure $x$-terms left have an exponent strictly less than $n$, by our remarks earlier about what $r_1, r_2$ contain. As we have noted earlier, we can replace $g$ with this new polynomial, since $(f, g) = (f, g - hf)$ for any $h$. 

Each time we perform this operation, we decrease the maximum degree of the pure $x$-terms in one of the curves. Thus we will eventually be left with a curve with no pure $x$-terms, which is therefore divisible by $y$, and we can move on to (3).

(3) If one of the curves (WLOG $f$) is divisible by $y$, then we can write $f = yf'$ and then, by additivity, get $\mu_0(f, g) = \mu_0(yf', g) = \mu_0(y, g) + \mu_0(f', g)$. The first term $\mu_0(y, g)$ can be computed using the result above, and is nonzero since $g$ passes through the origin. Thus $\mu_0(f', g)$ is less than $\mu_0(f, g)$, which gives us a guarantee that the algorithm will terminate: we won't get stuck in an infinite loop of step (3). 

## Examples
Let $f$ be the unit circle centered at $(-1, 0)$, $f = (x + 1)^2 + y^2 - 1$, and $g$ be the unit circle centered at $(1, 0)$, $g = (x - 1)^2 + y^2 - 1$. We will compute $\mu_0(f, g)$ using the algorithm above. 

Expanding things out fully, we have $f = x^2 + 2x + y^2, g = x^2 - 2x + y^2$. Then $\mu_0(f, g) = \mu_0(f, g - f) = \mu_0(f, -4x) = \mu_0(x^2 + 2x + y^2, -4x)$  (applying step (2)). Then we can kill the $x$-terms in $f$ using multiples of $-4x$ to get $\mu_0(y^2, -4x) = \mu_0(y, -4x) + \mu_0(y, -4x) = 1 + 1 = 2$. 

This is what we'd intuitively expect from the considerations in [[Intersections and Singular Points of Curves#Root Multiplicity and Secant Lines|this section above]], where we think of a multiplicity-$2$ intersection as the limit of two multiplicity-$1$ intersections. If you have two circles that overlap like a Venn diagram, then they intersect in two places, both with multiplicity $1$; if you pull them apart until they are tangent, then as you pull them, those two intersections approach each other and become a single intersection, which then has multiplicity $2$. 

# Smooth and Singular Points
Analytically, we can make a distinction between points at which a curve is smooth and points at which it isn't using the [[Differential Calculus in Rn#Implicit Function Theorem|Implicit Function Theorem]] or [[Manifolds#Regular Value Theorem|Regular Value Theorem]]. These tell us that a curve $f(x, y) = 0$ will look locally like a line as long as the differential $df$ is nonsingular, i.e. $\pd{f}{x}$ and $\pd{f}{y}$ are not both $0$. 

Another way to look at the situation is to note that a curve (passing through the origin, say) is best approximated near the origin by its lowest-degree nonzero terms. Thus, for example, if there are nonzero linear terms $ax + by$, we expect that, near the origin, any higher-order terms will be negligible and the curve will be like $ax + by$ locally, i.e. be like a line. Similarly it might look like a degree-2 curve near the origin if the linear terms are absent but some quadratic terms are present, and so on. 
## The Multiplicity of a Point
This motivates the following definition of the multiplicity of a point on a curve. First we introduce some notation. In a curve $f$, let $f_i$ be the "homogenous part of degree $i$", the sum of all the terms of $f$ with degree exactly $i$. Thus $f_1$ is the linear part, $f_2$ is the quadratic part, etc. and, if $f$ has degree $n$, then $f_n$ is the "leading part". If there are no terms of degree $i$, then we say $f_i = 0$. 

For a curve passing through the origin, we define the multiplicity of the point at the origin, denoted $m_0(f)$ to be the smallest $i$ for which $f_i$ is nonzero. For an arbitrary point $p$, we translate coordinates to move $p$ to $0$, and define the multiplicity $m_p(f)$ to be the multiplicity at $0$ in the new coordinates. 

When the multiplicity is equal to $1$, we say that $p$ is a smooth point on the curve; when it is equal to $0$, we say it is a singular point.

Like intersection multiplicity, the multiplicity of a point is additive: $m_0(fg) = m_0(f) + m_0(g)$, and the same for any other point. This is because, if $f = f_i + \dots + f_n$, and $g = g_j + \dots + g_m$, so that $m_0(f) = i$ and $m_0(g) = j$, the lowest-degree nonzero terms in $fg$ will come from $f_ig_j$, which has degree $i+j$. Thus $m_0(fg) = i + j = m_0(f) + m_0(g)$. 
## Tangent Lines
Let $m_0(f) = k$, so that $k$ is the smallest integer for which $f_k$ is nonzero. We say that any linear factor of $f_k$ is a tangent of $f$ at the origin. The idea is again that $f$ looks locally like $f_k$; at a smooth point, $m_0(f) = 1$, there can only be one tangent, which is just $f_1$ itself, while at a singular point, $f$ may be (though is not necessarily) locally like a union of several lines. 

To define tangents at other points $p$, we just translate $p$ to the origin, look for tangents at the origin (in the sense above), then translate those tangents back to $p$. 
## The Jacobi Criterion
The equivalence of this definition of a smooth/singular point to the analytic idea of a smooth point mentioned above is the content of the "affine Jacobi criterion": $f$ is smooth at $p$ if and only if the (formal) partial derivatives $\pd{f}{x}, \pd{f}{y}$ are not both zero at $p$. In that case, the (unique) tangent at $p = (x_0, y_0$) is given by $\pd{f}{x}(p)(x - x_0) + \pd{f}{y}(p)(y - y_0)$. 

Proof: Let $f = c + ax + by + \dots$ where the dots conceal all higher-order terms. Make the substitutions $x' = x - x_0, y' = y - y_0$, so that $f$, in these coordinates, becomes $f = ax' + by' + \dots$. (These substitutions translate $p$ to $0$, so $f$ in the new coordinates must pass through the origin, and so have a constant term of $0$). Clearly $\pd{f}{x'}(0) = a$ and $\pd{f}{y'}(0) = b$, so that $f_1$ is nonzero (i.e. $f$ is smooth at the origin, in the new coordinates) if and only if the partial derivatives are not both zero. But the partial derivatives at $p$ with respect to the original coordinates are also $a, b$, so $p$ is smooth if and only if they are not both zero. 

Also, when $p$ is smooth, the tangent at the origin (in the $x', y'$ coordinates) is $ax' + by'$, so the tangent at $p$ is $a(x - x_0) + b(y - y_0)$. 
## Types of Singular Points
### Points on Multiple Components
The least interesting kind of singular point arises when $f$ is reducible and has two components passing through the same point $p$. Say that $f = f_1f_2g$ with $f_1(0) = f_2(0) = 0$; then $m_0(f) = m_0(f_1) + m_0(f_2) + m_0(g) \geq 2$, so $0$ is a singular point of $f$. Thus, if $f$ has a repeated component, say $f = g^2h$, then all points on $g$ are singular. 
### Nodes
A node is a point of self-intersection where $f$ looks locally like two different lines. More formally, we say that $p$ is a node if $m_p(f) = 2$ (hence a node is a singular point) and $f$ has exactly two tangents through $p$. The [[Cubic Curves and Elliptic Curves#Folium|folium]] $x^3 + y^3 = 3xy$ is an example. We have $m_0(f) = 2$, since the nonzero part of least degree is the quadratic term $3xy$. The tangents through the origin are then $x$ and $y$, and indeed you can see on the graph that it is tangent to both the x-axis and y-axis at the origin. 
### Cusps
A cusp is a point of multiplicity $2$ through which there is exactly one tangent, which meets the curve with multiplicity $3$. The [[Cubic Curves and Elliptic Curves#Semicubical Parabola|semicubical parabola]] $y^2 = x^3$ is an example: $m_0(f) = 2$, on account of the quadratic term $y^2$, and the only linear factor of that quadratic term is $y$, so there is only one tangent, namely the x-axis. We then have $\mu_0(y, x^3) = 3$. 